{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Experiments\n",
    "\n",
    "### Scope\n",
    "In this notebook, we use one of the possible configurations of our LightGCNPlus model to experiment with different hyperparameters and configurations.\n",
    "\n",
    "### Purpose\n",
    "The purpose is to showcase why we fixed certain hyperparameters and configurations in the hyperparameter tuning loop in the LightGCNPlus.ipynb notebook.\n",
    "\n",
    "### Results\n",
    "Given the report results from the training we chose to fix the following hyperparameters and configurations:\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from train import train_model\n",
    "from models import LightGCNPlus\n",
    "from config import DEVICE\n",
    "from train import train_model\n",
    "from postprocess import report_training_results\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load import load_train_data\n",
    "train_df = load_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import preprocess\n",
    "\n",
    "# old: A_tilde, \\\n",
    "# standardized_train_ratings, \\\n",
    "# train_users, train_items, \\\n",
    "# means, stds, \\\n",
    "# val_users, \\\n",
    "# val_items, \\\n",
    "# orig_val_ratings, \\\n",
    "# standardized_val_ratings \\\n",
    "\n",
    "# new (but unformatted): A_tilde, train_users, train_items, train_ratings, val_users, val_items, val_ratings\n",
    "\n",
    "# new formatted\n",
    "\n",
    "A_tilde, \\\n",
    "train_users, train_items, train_ratings, \\\n",
    "val_users, val_items, val_ratings \\\n",
    "= preprocess(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and optimizer hyperparameters\n",
    "INIT_EMBS_STD=0.075\n",
    "LR=0.1\n",
    "WEIGHT_DECAY=0.00005\n",
    "DROPOUT=0.5\n",
    "ACT_FN = nn.GELU()\n",
    "\n",
    "# Train loop hyperparameters\n",
    "EPOCHS = 4000\n",
    "STOP_THRESHOLD=1e-09\n",
    "\n",
    "# To be searched (example values)\n",
    "# K=28\n",
    "# L=4\n",
    "# PROJECTIONS = (4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching over 1 combinations.\n"
     ]
    }
   ],
   "source": [
    "# Grid\n",
    "ks = [28]  # different Ks work with different projections\n",
    "layers = [5]  # tested 3 already\n",
    "projections = [(6,)]\n",
    "\n",
    "num_combinations = len(ks) * len(layers) * len(projections)\n",
    "print(f\"Searching over {num_combinations} combinations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=28, L=5, C=(6,)\n",
      "Epoch 1 - Avg loss in last 1 epochs: - Train: 3.7978 - Val: 1.3642 - Best val: 1.3642 at epoch 2\n",
      "Epoch 2 - Avg loss in last 1 epochs: - Train: 1.4846 - Val: 9.1415 - Best val: 1.3642 at epoch 2\n",
      "Epoch 3 - Avg loss in last 1 epochs: - Train: 9.2527 - Val: 1.5486 - Best val: 1.3642 at epoch 2\n",
      "Epoch 4 - Avg loss in last 1 epochs: - Train: 1.6803 - Val: 2.5276 - Best val: 1.3642 at epoch 2\n",
      "Epoch 5 - Avg loss in last 1 epochs: - Train: 2.5495 - Val: 2.8019 - Best val: 1.3642 at epoch 2\n",
      "Epoch 6 - Avg loss in last 1 epochs: - Train: 2.8179 - Val: 2.7773 - Best val: 1.3642 at epoch 2\n",
      "Epoch 7 - Avg loss in last 1 epochs: - Train: 2.8071 - Val: 2.6616 - Best val: 1.3642 at epoch 2\n",
      "Epoch 8 - Avg loss in last 1 epochs: - Train: 2.7240 - Val: 2.1516 - Best val: 1.3642 at epoch 2\n",
      "Epoch 9 - Avg loss in last 1 epochs: - Train: 2.3485 - Val: 2.2270 - Best val: 1.3642 at epoch 2\n",
      "Epoch 10 - Avg loss in last 1 epochs: - Train: 2.6168 - Val: 2.5992 - Best val: 1.3642 at epoch 2\n",
      "Epoch 11 - Avg loss in last 1 epochs: - Train: 2.9597 - Val: 3.0966 - Best val: 1.3642 at epoch 2\n",
      "Epoch 12 - Avg loss in last 1 epochs: - Train: 3.5494 - Val: 2.5956 - Best val: 1.3642 at epoch 2\n",
      "Epoch 13 - Avg loss in last 1 epochs: - Train: 2.9737 - Val: 1.5725 - Best val: 1.3642 at epoch 2\n",
      "Epoch 14 - Avg loss in last 1 epochs: - Train: 2.0138 - Val: 2.1130 - Best val: 1.3642 at epoch 2\n",
      "Epoch 15 - Avg loss in last 1 epochs: - Train: 2.4086 - Val: 1.4836 - Best val: 1.3642 at epoch 2\n",
      "Epoch 16 - Avg loss in last 1 epochs: - Train: 1.6841 - Val: 2.1979 - Best val: 1.3642 at epoch 2\n",
      "Epoch 17 - Avg loss in last 1 epochs: - Train: 2.2652 - Val: 1.5671 - Best val: 1.3642 at epoch 2\n",
      "Epoch 18 - Avg loss in last 1 epochs: - Train: 1.6610 - Val: 1.7745 - Best val: 1.3642 at epoch 2\n",
      "Epoch 19 - Avg loss in last 1 epochs: - Train: 1.8828 - Val: 1.5962 - Best val: 1.3642 at epoch 2\n",
      "Epoch 20 - Avg loss in last 1 epochs: - Train: 1.6698 - Val: 1.7496 - Best val: 1.3642 at epoch 2\n",
      "Epoch 21 - Avg loss in last 1 epochs: - Train: 1.7798 - Val: 1.7898 - Best val: 1.3642 at epoch 2\n",
      "Epoch 22 - Avg loss in last 1 epochs: - Train: 1.8161 - Val: 1.5165 - Best val: 1.3642 at epoch 2\n",
      "Epoch 23 - Avg loss in last 1 epochs: - Train: 1.5725 - Val: 1.6231 - Best val: 1.3642 at epoch 2\n",
      "Epoch 24 - Avg loss in last 1 epochs: - Train: 1.7003 - Val: 1.4620 - Best val: 1.3642 at epoch 2\n",
      "Epoch 25 - Avg loss in last 1 epochs: - Train: 1.5235 - Val: 1.5435 - Best val: 1.3642 at epoch 2\n",
      "Epoch 26 - Avg loss in last 1 epochs: - Train: 1.5746 - Val: 1.5551 - Best val: 1.3642 at epoch 2\n",
      "Epoch 27 - Avg loss in last 1 epochs: - Train: 1.5819 - Val: 1.2923 - Best val: 1.2923 at epoch 28\n",
      "Epoch 28 - Avg loss in last 1 epochs: - Train: 1.3464 - Val: 1.3641 - Best val: 1.2923 at epoch 28\n",
      "Epoch 29 - Avg loss in last 1 epochs: - Train: 1.4514 - Val: 1.3270 - Best val: 1.2923 at epoch 28\n",
      "Epoch 30 - Avg loss in last 1 epochs: - Train: 1.4127 - Val: 1.2587 - Best val: 1.2587 at epoch 31\n",
      "Epoch 31 - Avg loss in last 1 epochs: - Train: 1.3156 - Val: 1.3397 - Best val: 1.2587 at epoch 31\n",
      "Epoch 32 - Avg loss in last 1 epochs: - Train: 1.3824 - Val: 1.2317 - Best val: 1.2317 at epoch 33\n",
      "Epoch 33 - Avg loss in last 1 epochs: - Train: 1.2987 - Val: 1.1761 - Best val: 1.1761 at epoch 34\n",
      "Epoch 34 - Avg loss in last 1 epochs: - Train: 1.2903 - Val: 1.1984 - Best val: 1.1761 at epoch 34\n",
      "Epoch 35 - Avg loss in last 1 epochs: - Train: 1.3289 - Val: 1.1170 - Best val: 1.1170 at epoch 36\n",
      "Epoch 36 - Avg loss in last 1 epochs: - Train: 1.2396 - Val: 1.1407 - Best val: 1.1170 at epoch 36\n",
      "Epoch 37 - Avg loss in last 1 epochs: - Train: 1.2384 - Val: 1.1824 - Best val: 1.1170 at epoch 36\n",
      "Epoch 38 - Avg loss in last 1 epochs: - Train: 1.2751 - Val: 1.1175 - Best val: 1.1170 at epoch 36\n",
      "Epoch 39 - Avg loss in last 1 epochs: - Train: 1.2344 - Val: 1.0755 - Best val: 1.0755 at epoch 40\n",
      "Epoch 40 - Avg loss in last 1 epochs: - Train: 1.2226 - Val: 1.0771 - Best val: 1.0755 at epoch 40\n",
      "Epoch 41 - Avg loss in last 1 epochs: - Train: 1.2302 - Val: 1.0642 - Best val: 1.0642 at epoch 42\n",
      "Epoch 42 - Avg loss in last 1 epochs: - Train: 1.1995 - Val: 1.0873 - Best val: 1.0642 at epoch 42\n",
      "Epoch 43 - Avg loss in last 1 epochs: - Train: 1.1936 - Val: 1.1010 - Best val: 1.0642 at epoch 42\n",
      "Epoch 44 - Avg loss in last 1 epochs: - Train: 1.1919 - Val: 1.0607 - Best val: 1.0607 at epoch 45\n",
      "Epoch 45 - Avg loss in last 1 epochs: - Train: 1.1565 - Val: 1.0377 - Best val: 1.0377 at epoch 46\n",
      "Epoch 46 - Avg loss in last 1 epochs: - Train: 1.1475 - Val: 1.0446 - Best val: 1.0377 at epoch 46\n",
      "Epoch 47 - Avg loss in last 1 epochs: - Train: 1.1603 - Val: 1.0323 - Best val: 1.0323 at epoch 48\n",
      "Epoch 48 - Avg loss in last 1 epochs: - Train: 1.1426 - Val: 1.0327 - Best val: 1.0323 at epoch 48\n",
      "Epoch 49 - Avg loss in last 1 epochs: - Train: 1.1296 - Val: 1.0481 - Best val: 1.0323 at epoch 48\n",
      "Epoch 50 - Avg loss in last 1 epochs: - Train: 1.1343 - Val: 1.0412 - Best val: 1.0323 at epoch 48\n",
      "Epoch 51 - Avg loss in last 1 epochs: - Train: 1.1267 - Val: 1.0279 - Best val: 1.0279 at epoch 52\n",
      "Epoch 52 - Avg loss in last 1 epochs: - Train: 1.1181 - Val: 1.0248 - Best val: 1.0248 at epoch 53\n",
      "Epoch 53 - Avg loss in last 1 epochs: - Train: 1.1157 - Val: 1.0211 - Best val: 1.0211 at epoch 54\n",
      "Epoch 54 - Avg loss in last 1 epochs: - Train: 1.1052 - Val: 1.0271 - Best val: 1.0211 at epoch 54\n",
      "Epoch 55 - Avg loss in last 1 epochs: - Train: 1.0999 - Val: 1.0378 - Best val: 1.0211 at epoch 54\n",
      "Epoch 56 - Avg loss in last 1 epochs: - Train: 1.1024 - Val: 1.0294 - Best val: 1.0211 at epoch 54\n",
      "Epoch 57 - Avg loss in last 1 epochs: - Train: 1.0946 - Val: 1.0128 - Best val: 1.0128 at epoch 58\n",
      "Epoch 58 - Avg loss in last 1 epochs: - Train: 1.0854 - Val: 1.0089 - Best val: 1.0089 at epoch 59\n",
      "Epoch 59 - Avg loss in last 1 epochs: - Train: 1.0885 - Val: 1.0077 - Best val: 1.0077 at epoch 60\n",
      "Epoch 60 - Avg loss in last 1 epochs: - Train: 1.0880 - Val: 1.0063 - Best val: 1.0063 at epoch 61\n",
      "Epoch 61 - Avg loss in last 1 epochs: - Train: 1.0821 - Val: 1.0114 - Best val: 1.0063 at epoch 61\n",
      "Epoch 62 - Avg loss in last 1 epochs: - Train: 1.0811 - Val: 1.0113 - Best val: 1.0063 at epoch 61\n",
      "Epoch 63 - Avg loss in last 1 epochs: - Train: 1.0805 - Val: 1.0036 - Best val: 1.0036 at epoch 64\n",
      "Epoch 64 - Avg loss in last 1 epochs: - Train: 1.0752 - Val: 1.0002 - Best val: 1.0002 at epoch 65\n",
      "Epoch 65 - Avg loss in last 1 epochs: - Train: 1.0734 - Val: 1.0001 - Best val: 1.0001 at epoch 66\n",
      "Epoch 66 - Avg loss in last 1 epochs: - Train: 1.0728 - Val: 1.0012 - Best val: 1.0001 at epoch 66\n",
      "Epoch 67 - Avg loss in last 1 epochs: - Train: 1.0675 - Val: 1.0064 - Best val: 1.0001 at epoch 66\n",
      "Epoch 68 - Avg loss in last 1 epochs: - Train: 1.0678 - Val: 1.0086 - Best val: 1.0001 at epoch 66\n",
      "Epoch 69 - Avg loss in last 1 epochs: - Train: 1.0680 - Val: 1.0033 - Best val: 1.0001 at epoch 66\n",
      "Epoch 70 - Avg loss in last 1 epochs: - Train: 1.0648 - Val: 0.9978 - Best val: 0.9978 at epoch 71\n",
      "Epoch 71 - Avg loss in last 1 epochs: - Train: 1.0627 - Val: 0.9957 - Best val: 0.9957 at epoch 72\n",
      "Epoch 72 - Avg loss in last 1 epochs: - Train: 1.0623 - Val: 0.9955 - Best val: 0.9955 at epoch 73\n",
      "Epoch 73 - Avg loss in last 1 epochs: - Train: 1.0597 - Val: 0.9979 - Best val: 0.9955 at epoch 73\n",
      "Epoch 74 - Avg loss in last 1 epochs: - Train: 1.0589 - Val: 1.0006 - Best val: 0.9955 at epoch 73\n",
      "Epoch 75 - Avg loss in last 1 epochs: - Train: 1.0583 - Val: 0.9993 - Best val: 0.9955 at epoch 73\n",
      "Epoch 76 - Avg loss in last 1 epochs: - Train: 1.0570 - Val: 0.9962 - Best val: 0.9955 at epoch 73\n",
      "Epoch 77 - Avg loss in last 1 epochs: - Train: 1.0556 - Val: 0.9944 - Best val: 0.9944 at epoch 78\n",
      "Epoch 78 - Avg loss in last 1 epochs: - Train: 1.0548 - Val: 0.9940 - Best val: 0.9940 at epoch 79\n",
      "Epoch 79 - Avg loss in last 1 epochs: - Train: 1.0537 - Val: 0.9952 - Best val: 0.9940 at epoch 79\n",
      "Epoch 80 - Avg loss in last 1 epochs: - Train: 1.0528 - Val: 0.9970 - Best val: 0.9940 at epoch 79\n",
      "Epoch 81 - Avg loss in last 1 epochs: - Train: 1.0518 - Val: 0.9970 - Best val: 0.9940 at epoch 79\n",
      "Epoch 82 - Avg loss in last 1 epochs: - Train: 1.0509 - Val: 0.9956 - Best val: 0.9940 at epoch 79\n",
      "Epoch 83 - Avg loss in last 1 epochs: - Train: 1.0497 - Val: 0.9945 - Best val: 0.9940 at epoch 79\n",
      "Epoch 84 - Avg loss in last 1 epochs: - Train: 1.0486 - Val: 0.9938 - Best val: 0.9938 at epoch 85\n",
      "Epoch 85 - Avg loss in last 1 epochs: - Train: 1.0479 - Val: 0.9934 - Best val: 0.9934 at epoch 86\n",
      "Epoch 86 - Avg loss in last 1 epochs: - Train: 1.0470 - Val: 0.9937 - Best val: 0.9934 at epoch 86\n",
      "Epoch 87 - Avg loss in last 1 epochs: - Train: 1.0465 - Val: 0.9933 - Best val: 0.9933 at epoch 88\n",
      "Epoch 88 - Avg loss in last 1 epochs: - Train: 1.0458 - Val: 0.9920 - Best val: 0.9920 at epoch 89\n",
      "Epoch 89 - Avg loss in last 1 epochs: - Train: 1.0451 - Val: 0.9913 - Best val: 0.9913 at epoch 90\n",
      "Epoch 90 - Avg loss in last 1 epochs: - Train: 1.0446 - Val: 0.9917 - Best val: 0.9913 at epoch 90\n",
      "Epoch 91 - Avg loss in last 1 epochs: - Train: 1.0434 - Val: 0.9928 - Best val: 0.9913 at epoch 90\n",
      "Epoch 92 - Avg loss in last 1 epochs: - Train: 1.0429 - Val: 0.9940 - Best val: 0.9913 at epoch 90\n",
      "Epoch 93 - Avg loss in last 1 epochs: - Train: 1.0419 - Val: 0.9943 - Best val: 0.9913 at epoch 90\n",
      "Epoch 94 - Avg loss in last 1 epochs: - Train: 1.0420 - Val: 0.9933 - Best val: 0.9913 at epoch 90\n",
      "Epoch 95 - Avg loss in last 1 epochs: - Train: 1.0408 - Val: 0.9921 - Best val: 0.9913 at epoch 90\n",
      "Epoch 96 - Avg loss in last 1 epochs: - Train: 1.0411 - Val: 0.9915 - Best val: 0.9913 at epoch 90\n",
      "Epoch 97 - Avg loss in last 1 epochs: - Train: 1.0398 - Val: 0.9916 - Best val: 0.9913 at epoch 90\n",
      "Epoch 98 - Avg loss in last 1 epochs: - Train: 1.0393 - Val: 0.9922 - Best val: 0.9913 at epoch 90\n",
      "Epoch 99 - Avg loss in last 1 epochs: - Train: 1.0386 - Val: 0.9924 - Best val: 0.9913 at epoch 90\n",
      "Epoch 100 - Avg loss in last 1 epochs: - Train: 1.0387 - Val: 0.9918 - Best val: 0.9913 at epoch 90\n",
      "Epoch 101 - Avg loss in last 1 epochs: - Train: 1.0373 - Val: 0.9909 - Best val: 0.9909 at epoch 102\n",
      "Epoch 102 - Avg loss in last 1 epochs: - Train: 1.0372 - Val: 0.9904 - Best val: 0.9904 at epoch 103\n",
      "Epoch 103 - Avg loss in last 1 epochs: - Train: 1.0365 - Val: 0.9904 - Best val: 0.9904 at epoch 103\n",
      "Epoch 104 - Avg loss in last 1 epochs: - Train: 1.0363 - Val: 0.9909 - Best val: 0.9904 at epoch 103\n",
      "Epoch 105 - Avg loss in last 1 epochs: - Train: 1.0349 - Val: 0.9913 - Best val: 0.9904 at epoch 103\n",
      "Epoch 106 - Avg loss in last 1 epochs: - Train: 1.0352 - Val: 0.9912 - Best val: 0.9904 at epoch 103\n",
      "Epoch 107 - Avg loss in last 1 epochs: - Train: 1.0349 - Val: 0.9907 - Best val: 0.9904 at epoch 103\n",
      "Epoch 108 - Avg loss in last 1 epochs: - Train: 1.0335 - Val: 0.9902 - Best val: 0.9902 at epoch 109\n",
      "Epoch 109 - Avg loss in last 1 epochs: - Train: 1.0335 - Val: 0.9902 - Best val: 0.9902 at epoch 110\n",
      "Epoch 110 - Avg loss in last 1 epochs: - Train: 1.0329 - Val: 0.9905 - Best val: 0.9902 at epoch 110\n",
      "Epoch 111 - Avg loss in last 1 epochs: - Train: 1.0323 - Val: 0.9908 - Best val: 0.9902 at epoch 110\n",
      "Epoch 112 - Avg loss in last 1 epochs: - Train: 1.0320 - Val: 0.9907 - Best val: 0.9902 at epoch 110\n",
      "Epoch 113 - Avg loss in last 1 epochs: - Train: 1.0320 - Val: 0.9904 - Best val: 0.9902 at epoch 110\n",
      "Epoch 114 - Avg loss in last 1 epochs: - Train: 1.0315 - Val: 0.9900 - Best val: 0.9900 at epoch 115\n",
      "Epoch 115 - Avg loss in last 1 epochs: - Train: 1.0306 - Val: 0.9897 - Best val: 0.9897 at epoch 116\n",
      "Epoch 116 - Avg loss in last 1 epochs: - Train: 1.0302 - Val: 0.9896 - Best val: 0.9896 at epoch 117\n",
      "Epoch 117 - Avg loss in last 1 epochs: - Train: 1.0297 - Val: 0.9894 - Best val: 0.9894 at epoch 118\n",
      "Epoch 118 - Avg loss in last 1 epochs: - Train: 1.0300 - Val: 0.9893 - Best val: 0.9893 at epoch 119\n",
      "Epoch 119 - Avg loss in last 1 epochs: - Train: 1.0287 - Val: 0.9894 - Best val: 0.9893 at epoch 119\n",
      "Epoch 120 - Avg loss in last 1 epochs: - Train: 1.0281 - Val: 0.9896 - Best val: 0.9893 at epoch 119\n",
      "Epoch 121 - Avg loss in last 1 epochs: - Train: 1.0285 - Val: 0.9900 - Best val: 0.9893 at epoch 119\n",
      "Epoch 122 - Avg loss in last 1 epochs: - Train: 1.0278 - Val: 0.9902 - Best val: 0.9893 at epoch 119\n",
      "Epoch 123 - Avg loss in last 1 epochs: - Train: 1.0269 - Val: 0.9902 - Best val: 0.9893 at epoch 119\n",
      "Epoch 124 - Avg loss in last 1 epochs: - Train: 1.0269 - Val: 0.9900 - Best val: 0.9893 at epoch 119\n",
      "Epoch 125 - Avg loss in last 1 epochs: - Train: 1.0268 - Val: 0.9898 - Best val: 0.9893 at epoch 119\n",
      "Epoch 126 - Avg loss in last 1 epochs: - Train: 1.0259 - Val: 0.9898 - Best val: 0.9893 at epoch 119\n",
      "Epoch 127 - Avg loss in last 1 epochs: - Train: 1.0258 - Val: 0.9899 - Best val: 0.9893 at epoch 119\n",
      "Epoch 128 - Avg loss in last 1 epochs: - Train: 1.0258 - Val: 0.9902 - Best val: 0.9893 at epoch 119\n",
      "Epoch 129 - Avg loss in last 1 epochs: - Train: 1.0251 - Val: 0.9902 - Best val: 0.9893 at epoch 119\n",
      "Epoch 130 - Avg loss in last 1 epochs: - Train: 1.0249 - Val: 0.9900 - Best val: 0.9893 at epoch 119\n",
      "Epoch 131 - Avg loss in last 1 epochs: - Train: 1.0242 - Val: 0.9896 - Best val: 0.9893 at epoch 119\n",
      "Epoch 132 - Avg loss in last 1 epochs: - Train: 1.0239 - Val: 0.9892 - Best val: 0.9892 at epoch 133\n",
      "Epoch 133 - Avg loss in last 1 epochs: - Train: 1.0239 - Val: 0.9888 - Best val: 0.9888 at epoch 134\n",
      "Epoch 134 - Avg loss in last 1 epochs: - Train: 1.0233 - Val: 0.9887 - Best val: 0.9887 at epoch 135\n",
      "Epoch 135 - Avg loss in last 1 epochs: - Train: 1.0234 - Val: 0.9890 - Best val: 0.9887 at epoch 135\n",
      "Epoch 136 - Avg loss in last 1 epochs: - Train: 1.0230 - Val: 0.9897 - Best val: 0.9887 at epoch 135\n",
      "Epoch 137 - Avg loss in last 1 epochs: - Train: 1.0225 - Val: 0.9901 - Best val: 0.9887 at epoch 135\n",
      "Epoch 138 - Avg loss in last 1 epochs: - Train: 1.0222 - Val: 0.9904 - Best val: 0.9887 at epoch 135\n",
      "Epoch 139 - Avg loss in last 1 epochs: - Train: 1.0221 - Val: 0.9904 - Best val: 0.9887 at epoch 135\n",
      "Epoch 140 - Avg loss in last 1 epochs: - Train: 1.0217 - Val: 0.9899 - Best val: 0.9887 at epoch 135\n",
      "Epoch 141 - Avg loss in last 1 epochs: - Train: 1.0214 - Val: 0.9894 - Best val: 0.9887 at epoch 135\n",
      "Epoch 142 - Avg loss in last 1 epochs: - Train: 1.0206 - Val: 0.9888 - Best val: 0.9887 at epoch 135\n",
      "Epoch 143 - Avg loss in last 1 epochs: - Train: 1.0203 - Val: 0.9887 - Best val: 0.9887 at epoch 135\n",
      "Epoch 144 - Avg loss in last 1 epochs: - Train: 1.0202 - Val: 0.9887 - Best val: 0.9887 at epoch 135\n",
      "Epoch 145 - Avg loss in last 1 epochs: - Train: 1.0197 - Val: 0.9888 - Best val: 0.9887 at epoch 135\n",
      "Epoch 146 - Avg loss in last 1 epochs: - Train: 1.0189 - Val: 0.9888 - Best val: 0.9887 at epoch 135\n",
      "Epoch 147 - Avg loss in last 1 epochs: - Train: 1.0189 - Val: 0.9890 - Best val: 0.9887 at epoch 135\n",
      "Epoch 148 - Avg loss in last 1 epochs: - Train: 1.0185 - Val: 0.9892 - Best val: 0.9887 at epoch 135\n",
      "Epoch 149 - Avg loss in last 1 epochs: - Train: 1.0183 - Val: 0.9894 - Best val: 0.9887 at epoch 135\n",
      "Epoch 150 - Avg loss in last 1 epochs: - Train: 1.0179 - Val: 0.9894 - Best val: 0.9887 at epoch 135\n",
      "Epoch 151 - Avg loss in last 1 epochs: - Train: 1.0175 - Val: 0.9893 - Best val: 0.9887 at epoch 135\n",
      "Epoch 152 - Avg loss in last 1 epochs: - Train: 1.0172 - Val: 0.9890 - Best val: 0.9887 at epoch 135\n",
      "Epoch 153 - Avg loss in last 1 epochs: - Train: 1.0172 - Val: 0.9888 - Best val: 0.9887 at epoch 135\n",
      "Epoch 154 - Avg loss in last 1 epochs: - Train: 1.0170 - Val: 0.9886 - Best val: 0.9886 at epoch 155\n",
      "Epoch 155 - Avg loss in last 1 epochs: - Train: 1.0167 - Val: 0.9888 - Best val: 0.9886 at epoch 155\n",
      "Epoch 156 - Avg loss in last 1 epochs: - Train: 1.0165 - Val: 0.9893 - Best val: 0.9886 at epoch 155\n",
      "Epoch 157 - Avg loss in last 1 epochs: - Train: 1.0163 - Val: 0.9897 - Best val: 0.9886 at epoch 155\n",
      "Epoch 158 - Avg loss in last 1 epochs: - Train: 1.0159 - Val: 0.9898 - Best val: 0.9886 at epoch 155\n",
      "Epoch 159 - Avg loss in last 1 epochs: - Train: 1.0150 - Val: 0.9894 - Best val: 0.9886 at epoch 155\n",
      "Epoch 160 - Avg loss in last 1 epochs: - Train: 1.0153 - Val: 0.9891 - Best val: 0.9886 at epoch 155\n",
      "Epoch 161 - Avg loss in last 1 epochs: - Train: 1.0144 - Val: 0.9887 - Best val: 0.9886 at epoch 155\n",
      "Epoch 162 - Avg loss in last 1 epochs: - Train: 1.0146 - Val: 0.9886 - Best val: 0.9886 at epoch 163\n",
      "Epoch 163 - Avg loss in last 1 epochs: - Train: 1.0139 - Val: 0.9885 - Best val: 0.9885 at epoch 164\n",
      "Epoch 164 - Avg loss in last 1 epochs: - Train: 1.0140 - Val: 0.9884 - Best val: 0.9884 at epoch 165\n",
      "Epoch 165 - Avg loss in last 1 epochs: - Train: 1.0138 - Val: 0.9885 - Best val: 0.9884 at epoch 165\n",
      "Epoch 166 - Avg loss in last 1 epochs: - Train: 1.0131 - Val: 0.9887 - Best val: 0.9884 at epoch 165\n",
      "Epoch 167 - Avg loss in last 1 epochs: - Train: 1.0129 - Val: 0.9889 - Best val: 0.9884 at epoch 165\n",
      "Epoch 168 - Avg loss in last 1 epochs: - Train: 1.0130 - Val: 0.9888 - Best val: 0.9884 at epoch 165\n",
      "Epoch 169 - Avg loss in last 1 epochs: - Train: 1.0128 - Val: 0.9887 - Best val: 0.9884 at epoch 165\n",
      "Epoch 170 - Avg loss in last 1 epochs: - Train: 1.0121 - Val: 0.9885 - Best val: 0.9884 at epoch 165\n",
      "Epoch 171 - Avg loss in last 1 epochs: - Train: 1.0122 - Val: 0.9885 - Best val: 0.9884 at epoch 165\n",
      "Epoch 172 - Avg loss in last 1 epochs: - Train: 1.0119 - Val: 0.9888 - Best val: 0.9884 at epoch 165\n",
      "Epoch 173 - Avg loss in last 1 epochs: - Train: 1.0117 - Val: 0.9890 - Best val: 0.9884 at epoch 165\n",
      "Epoch 174 - Avg loss in last 1 epochs: - Train: 1.0112 - Val: 0.9891 - Best val: 0.9884 at epoch 165\n",
      "Epoch 175 - Avg loss in last 1 epochs: - Train: 1.0110 - Val: 0.9890 - Best val: 0.9884 at epoch 165\n",
      "Epoch 176 - Avg loss in last 1 epochs: - Train: 1.0106 - Val: 0.9886 - Best val: 0.9884 at epoch 165\n",
      "Epoch 177 - Avg loss in last 1 epochs: - Train: 1.0107 - Val: 0.9883 - Best val: 0.9883 at epoch 178\n",
      "Epoch 178 - Avg loss in last 1 epochs: - Train: 1.0102 - Val: 0.9882 - Best val: 0.9882 at epoch 179\n",
      "Epoch 179 - Avg loss in last 1 epochs: - Train: 1.0100 - Val: 0.9883 - Best val: 0.9882 at epoch 179\n",
      "Epoch 180 - Avg loss in last 1 epochs: - Train: 1.0096 - Val: 0.9886 - Best val: 0.9882 at epoch 179\n",
      "Epoch 181 - Avg loss in last 1 epochs: - Train: 1.0098 - Val: 0.9888 - Best val: 0.9882 at epoch 179\n",
      "Epoch 182 - Avg loss in last 1 epochs: - Train: 1.0095 - Val: 0.9889 - Best val: 0.9882 at epoch 179\n",
      "Epoch 183 - Avg loss in last 1 epochs: - Train: 1.0094 - Val: 0.9888 - Best val: 0.9882 at epoch 179\n",
      "Epoch 184 - Avg loss in last 1 epochs: - Train: 1.0089 - Val: 0.9886 - Best val: 0.9882 at epoch 179\n",
      "Epoch 185 - Avg loss in last 1 epochs: - Train: 1.0087 - Val: 0.9884 - Best val: 0.9882 at epoch 179\n",
      "Epoch 186 - Avg loss in last 1 epochs: - Train: 1.0085 - Val: 0.9884 - Best val: 0.9882 at epoch 179\n",
      "Epoch 187 - Avg loss in last 1 epochs: - Train: 1.0083 - Val: 0.9884 - Best val: 0.9882 at epoch 179\n",
      "Epoch 188 - Avg loss in last 1 epochs: - Train: 1.0081 - Val: 0.9885 - Best val: 0.9882 at epoch 179\n",
      "Epoch 189 - Avg loss in last 1 epochs: - Train: 1.0080 - Val: 0.9886 - Best val: 0.9882 at epoch 179\n",
      "Epoch 190 - Avg loss in last 1 epochs: - Train: 1.0079 - Val: 0.9886 - Best val: 0.9882 at epoch 179\n",
      "Epoch 191 - Avg loss in last 1 epochs: - Train: 1.0076 - Val: 0.9885 - Best val: 0.9882 at epoch 179\n",
      "Epoch 192 - Avg loss in last 1 epochs: - Train: 1.0071 - Val: 0.9884 - Best val: 0.9882 at epoch 179\n",
      "Epoch 193 - Avg loss in last 1 epochs: - Train: 1.0072 - Val: 0.9884 - Best val: 0.9882 at epoch 179\n",
      "Epoch 194 - Avg loss in last 1 epochs: - Train: 1.0071 - Val: 0.9886 - Best val: 0.9882 at epoch 179\n",
      "Epoch 195 - Avg loss in last 1 epochs: - Train: 1.0065 - Val: 0.9885 - Best val: 0.9882 at epoch 179\n",
      "Epoch 196 - Avg loss in last 1 epochs: - Train: 1.0064 - Val: 0.9884 - Best val: 0.9882 at epoch 179\n",
      "Epoch 197 - Avg loss in last 1 epochs: - Train: 1.0064 - Val: 0.9883 - Best val: 0.9882 at epoch 179\n",
      "Epoch 198 - Avg loss in last 1 epochs: - Train: 1.0063 - Val: 0.9884 - Best val: 0.9882 at epoch 179\n",
      "Epoch 199 - Avg loss in last 1 epochs: - Train: 1.0060 - Val: 0.9885 - Best val: 0.9882 at epoch 179\n",
      "Epoch 200 - Avg loss in last 1 epochs: - Train: 1.0055 - Val: 0.9885 - Best val: 0.9882 at epoch 179\n",
      "Epoch 201 - Avg loss in last 1 epochs: - Train: 1.0055 - Val: 0.9883 - Best val: 0.9882 at epoch 179\n",
      "Epoch 202 - Avg loss in last 1 epochs: - Train: 1.0052 - Val: 0.9881 - Best val: 0.9881 at epoch 203\n",
      "Epoch 203 - Avg loss in last 1 epochs: - Train: 1.0054 - Val: 0.9880 - Best val: 0.9880 at epoch 204\n",
      "Epoch 204 - Avg loss in last 1 epochs: - Train: 1.0052 - Val: 0.9882 - Best val: 0.9880 at epoch 204\n",
      "Epoch 205 - Avg loss in last 1 epochs: - Train: 1.0049 - Val: 0.9883 - Best val: 0.9880 at epoch 204\n",
      "Epoch 206 - Avg loss in last 1 epochs: - Train: 1.0049 - Val: 0.9884 - Best val: 0.9880 at epoch 204\n",
      "Epoch 207 - Avg loss in last 1 epochs: - Train: 1.0045 - Val: 0.9883 - Best val: 0.9880 at epoch 204\n",
      "Epoch 208 - Avg loss in last 1 epochs: - Train: 1.0047 - Val: 0.9882 - Best val: 0.9880 at epoch 204\n",
      "Epoch 209 - Avg loss in last 1 epochs: - Train: 1.0047 - Val: 0.9879 - Best val: 0.9879 at epoch 210\n",
      "Epoch 210 - Avg loss in last 1 epochs: - Train: 1.0042 - Val: 0.9877 - Best val: 0.9877 at epoch 211\n",
      "Epoch 211 - Avg loss in last 1 epochs: - Train: 1.0043 - Val: 0.9876 - Best val: 0.9876 at epoch 212\n",
      "Epoch 212 - Avg loss in last 1 epochs: - Train: 1.0039 - Val: 0.9877 - Best val: 0.9876 at epoch 212\n",
      "Epoch 213 - Avg loss in last 1 epochs: - Train: 1.0033 - Val: 0.9878 - Best val: 0.9876 at epoch 212\n",
      "Epoch 214 - Avg loss in last 1 epochs: - Train: 1.0034 - Val: 0.9878 - Best val: 0.9876 at epoch 212\n",
      "Epoch 215 - Avg loss in last 1 epochs: - Train: 1.0029 - Val: 0.9880 - Best val: 0.9876 at epoch 212\n",
      "Epoch 216 - Avg loss in last 1 epochs: - Train: 1.0030 - Val: 0.9881 - Best val: 0.9876 at epoch 212\n",
      "Epoch 217 - Avg loss in last 1 epochs: - Train: 1.0031 - Val: 0.9879 - Best val: 0.9876 at epoch 212\n",
      "Epoch 218 - Avg loss in last 1 epochs: - Train: 1.0032 - Val: 0.9877 - Best val: 0.9876 at epoch 212\n",
      "Epoch 219 - Avg loss in last 1 epochs: - Train: 1.0029 - Val: 0.9874 - Best val: 0.9874 at epoch 220\n",
      "Epoch 220 - Avg loss in last 1 epochs: - Train: 1.0025 - Val: 0.9873 - Best val: 0.9873 at epoch 221\n",
      "Epoch 221 - Avg loss in last 1 epochs: - Train: 1.0022 - Val: 0.9872 - Best val: 0.9872 at epoch 222\n",
      "Epoch 222 - Avg loss in last 1 epochs: - Train: 1.0023 - Val: 0.9871 - Best val: 0.9871 at epoch 223\n",
      "Epoch 223 - Avg loss in last 1 epochs: - Train: 1.0022 - Val: 0.9871 - Best val: 0.9871 at epoch 224\n",
      "Epoch 224 - Avg loss in last 1 epochs: - Train: 1.0020 - Val: 0.9871 - Best val: 0.9871 at epoch 224\n",
      "Epoch 225 - Avg loss in last 1 epochs: - Train: 1.0021 - Val: 0.9873 - Best val: 0.9871 at epoch 224\n",
      "Epoch 226 - Avg loss in last 1 epochs: - Train: 1.0017 - Val: 0.9874 - Best val: 0.9871 at epoch 224\n",
      "Epoch 227 - Avg loss in last 1 epochs: - Train: 1.0016 - Val: 0.9875 - Best val: 0.9871 at epoch 224\n",
      "Epoch 228 - Avg loss in last 1 epochs: - Train: 1.0017 - Val: 0.9875 - Best val: 0.9871 at epoch 224\n",
      "Epoch 229 - Avg loss in last 1 epochs: - Train: 1.0012 - Val: 0.9874 - Best val: 0.9871 at epoch 224\n",
      "Epoch 230 - Avg loss in last 1 epochs: - Train: 1.0013 - Val: 0.9872 - Best val: 0.9871 at epoch 224\n",
      "Epoch 231 - Avg loss in last 1 epochs: - Train: 1.0009 - Val: 0.9871 - Best val: 0.9871 at epoch 232\n",
      "Epoch 232 - Avg loss in last 1 epochs: - Train: 1.0010 - Val: 0.9870 - Best val: 0.9870 at epoch 233\n",
      "Epoch 233 - Avg loss in last 1 epochs: - Train: 1.0011 - Val: 0.9869 - Best val: 0.9869 at epoch 234\n",
      "Epoch 234 - Avg loss in last 1 epochs: - Train: 1.0009 - Val: 0.9868 - Best val: 0.9868 at epoch 235\n",
      "Epoch 235 - Avg loss in last 1 epochs: - Train: 1.0006 - Val: 0.9868 - Best val: 0.9868 at epoch 236\n",
      "Epoch 236 - Avg loss in last 1 epochs: - Train: 1.0005 - Val: 0.9869 - Best val: 0.9868 at epoch 236\n",
      "Epoch 237 - Avg loss in last 1 epochs: - Train: 1.0004 - Val: 0.9870 - Best val: 0.9868 at epoch 236\n",
      "Epoch 238 - Avg loss in last 1 epochs: - Train: 1.0001 - Val: 0.9872 - Best val: 0.9868 at epoch 236\n",
      "Epoch 239 - Avg loss in last 1 epochs: - Train: 1.0000 - Val: 0.9871 - Best val: 0.9868 at epoch 236\n",
      "Epoch 240 - Avg loss in last 1 epochs: - Train: 1.0003 - Val: 0.9870 - Best val: 0.9868 at epoch 236\n",
      "Epoch 241 - Avg loss in last 1 epochs: - Train: 1.0000 - Val: 0.9869 - Best val: 0.9868 at epoch 236\n",
      "Epoch 242 - Avg loss in last 1 epochs: - Train: 0.9996 - Val: 0.9868 - Best val: 0.9868 at epoch 243\n",
      "Epoch 243 - Avg loss in last 1 epochs: - Train: 0.9998 - Val: 0.9868 - Best val: 0.9868 at epoch 243\n",
      "Epoch 244 - Avg loss in last 1 epochs: - Train: 0.9996 - Val: 0.9870 - Best val: 0.9868 at epoch 243\n",
      "Epoch 245 - Avg loss in last 1 epochs: - Train: 0.9996 - Val: 0.9873 - Best val: 0.9868 at epoch 243\n",
      "Epoch 246 - Avg loss in last 1 epochs: - Train: 0.9991 - Val: 0.9873 - Best val: 0.9868 at epoch 243\n",
      "Epoch 247 - Avg loss in last 1 epochs: - Train: 0.9995 - Val: 0.9871 - Best val: 0.9868 at epoch 243\n",
      "Epoch 248 - Avg loss in last 1 epochs: - Train: 0.9993 - Val: 0.9867 - Best val: 0.9867 at epoch 249\n",
      "Epoch 249 - Avg loss in last 1 epochs: - Train: 0.9990 - Val: 0.9865 - Best val: 0.9865 at epoch 250\n",
      "Epoch 250 - Avg loss in last 1 epochs: - Train: 0.9992 - Val: 0.9864 - Best val: 0.9864 at epoch 251\n",
      "Epoch 251 - Avg loss in last 1 epochs: - Train: 0.9988 - Val: 0.9866 - Best val: 0.9864 at epoch 251\n",
      "Epoch 252 - Avg loss in last 1 epochs: - Train: 0.9988 - Val: 0.9866 - Best val: 0.9864 at epoch 251\n",
      "Epoch 253 - Avg loss in last 1 epochs: - Train: 0.9986 - Val: 0.9867 - Best val: 0.9864 at epoch 251\n",
      "Epoch 254 - Avg loss in last 1 epochs: - Train: 0.9985 - Val: 0.9868 - Best val: 0.9864 at epoch 251\n",
      "Epoch 255 - Avg loss in last 1 epochs: - Train: 0.9987 - Val: 0.9869 - Best val: 0.9864 at epoch 251\n",
      "Epoch 256 - Avg loss in last 1 epochs: - Train: 0.9985 - Val: 0.9869 - Best val: 0.9864 at epoch 251\n",
      "Epoch 257 - Avg loss in last 1 epochs: - Train: 0.9980 - Val: 0.9869 - Best val: 0.9864 at epoch 251\n",
      "Epoch 258 - Avg loss in last 1 epochs: - Train: 0.9984 - Val: 0.9870 - Best val: 0.9864 at epoch 251\n",
      "Epoch 259 - Avg loss in last 1 epochs: - Train: 0.9980 - Val: 0.9868 - Best val: 0.9864 at epoch 251\n",
      "Epoch 260 - Avg loss in last 1 epochs: - Train: 0.9980 - Val: 0.9866 - Best val: 0.9864 at epoch 251\n",
      "Epoch 261 - Avg loss in last 1 epochs: - Train: 0.9978 - Val: 0.9863 - Best val: 0.9863 at epoch 262\n",
      "Epoch 262 - Avg loss in last 1 epochs: - Train: 0.9982 - Val: 0.9862 - Best val: 0.9862 at epoch 263\n",
      "Epoch 263 - Avg loss in last 1 epochs: - Train: 0.9979 - Val: 0.9861 - Best val: 0.9861 at epoch 264\n",
      "Epoch 264 - Avg loss in last 1 epochs: - Train: 0.9978 - Val: 0.9862 - Best val: 0.9861 at epoch 264\n",
      "Epoch 265 - Avg loss in last 1 epochs: - Train: 0.9976 - Val: 0.9863 - Best val: 0.9861 at epoch 264\n",
      "Epoch 266 - Avg loss in last 1 epochs: - Train: 0.9974 - Val: 0.9863 - Best val: 0.9861 at epoch 264\n",
      "Epoch 267 - Avg loss in last 1 epochs: - Train: 0.9974 - Val: 0.9864 - Best val: 0.9861 at epoch 264\n",
      "Epoch 268 - Avg loss in last 1 epochs: - Train: 0.9972 - Val: 0.9865 - Best val: 0.9861 at epoch 264\n",
      "Epoch 269 - Avg loss in last 1 epochs: - Train: 0.9972 - Val: 0.9865 - Best val: 0.9861 at epoch 264\n",
      "Epoch 270 - Avg loss in last 1 epochs: - Train: 0.9973 - Val: 0.9863 - Best val: 0.9861 at epoch 264\n",
      "Epoch 271 - Avg loss in last 1 epochs: - Train: 0.9970 - Val: 0.9862 - Best val: 0.9861 at epoch 264\n",
      "Epoch 272 - Avg loss in last 1 epochs: - Train: 0.9972 - Val: 0.9862 - Best val: 0.9861 at epoch 264\n",
      "Epoch 273 - Avg loss in last 1 epochs: - Train: 0.9970 - Val: 0.9861 - Best val: 0.9861 at epoch 264\n",
      "Epoch 274 - Avg loss in last 1 epochs: - Train: 0.9968 - Val: 0.9860 - Best val: 0.9860 at epoch 275\n",
      "Epoch 275 - Avg loss in last 1 epochs: - Train: 0.9967 - Val: 0.9858 - Best val: 0.9858 at epoch 276\n",
      "Epoch 276 - Avg loss in last 1 epochs: - Train: 0.9964 - Val: 0.9857 - Best val: 0.9857 at epoch 277\n",
      "Epoch 277 - Avg loss in last 1 epochs: - Train: 0.9967 - Val: 0.9857 - Best val: 0.9857 at epoch 277\n",
      "Epoch 278 - Avg loss in last 1 epochs: - Train: 0.9966 - Val: 0.9859 - Best val: 0.9857 at epoch 277\n",
      "Epoch 279 - Avg loss in last 1 epochs: - Train: 0.9962 - Val: 0.9862 - Best val: 0.9857 at epoch 277\n",
      "Epoch 280 - Avg loss in last 1 epochs: - Train: 0.9963 - Val: 0.9863 - Best val: 0.9857 at epoch 277\n",
      "Epoch 281 - Avg loss in last 1 epochs: - Train: 0.9962 - Val: 0.9863 - Best val: 0.9857 at epoch 277\n",
      "Epoch 282 - Avg loss in last 1 epochs: - Train: 0.9960 - Val: 0.9864 - Best val: 0.9857 at epoch 277\n",
      "Epoch 283 - Avg loss in last 1 epochs: - Train: 0.9965 - Val: 0.9862 - Best val: 0.9857 at epoch 277\n",
      "Epoch 284 - Avg loss in last 1 epochs: - Train: 0.9961 - Val: 0.9861 - Best val: 0.9857 at epoch 277\n",
      "Epoch 285 - Avg loss in last 1 epochs: - Train: 0.9958 - Val: 0.9858 - Best val: 0.9857 at epoch 277\n",
      "Epoch 286 - Avg loss in last 1 epochs: - Train: 0.9958 - Val: 0.9856 - Best val: 0.9856 at epoch 287\n",
      "Epoch 287 - Avg loss in last 1 epochs: - Train: 0.9958 - Val: 0.9854 - Best val: 0.9854 at epoch 288\n",
      "Epoch 288 - Avg loss in last 1 epochs: - Train: 0.9958 - Val: 0.9854 - Best val: 0.9854 at epoch 288\n",
      "Epoch 289 - Avg loss in last 1 epochs: - Train: 0.9956 - Val: 0.9854 - Best val: 0.9854 at epoch 288\n",
      "Epoch 290 - Avg loss in last 1 epochs: - Train: 0.9957 - Val: 0.9854 - Best val: 0.9854 at epoch 291\n",
      "Epoch 291 - Avg loss in last 1 epochs: - Train: 0.9955 - Val: 0.9854 - Best val: 0.9854 at epoch 291\n",
      "Epoch 292 - Avg loss in last 1 epochs: - Train: 0.9954 - Val: 0.9854 - Best val: 0.9854 at epoch 291\n",
      "Epoch 293 - Avg loss in last 1 epochs: - Train: 0.9953 - Val: 0.9855 - Best val: 0.9854 at epoch 291\n",
      "Epoch 294 - Avg loss in last 1 epochs: - Train: 0.9954 - Val: 0.9855 - Best val: 0.9854 at epoch 291\n",
      "Epoch 295 - Avg loss in last 1 epochs: - Train: 0.9952 - Val: 0.9855 - Best val: 0.9854 at epoch 291\n",
      "Epoch 296 - Avg loss in last 1 epochs: - Train: 0.9953 - Val: 0.9856 - Best val: 0.9854 at epoch 291\n",
      "Epoch 297 - Avg loss in last 1 epochs: - Train: 0.9953 - Val: 0.9856 - Best val: 0.9854 at epoch 291\n",
      "Epoch 298 - Avg loss in last 1 epochs: - Train: 0.9951 - Val: 0.9856 - Best val: 0.9854 at epoch 291\n",
      "Epoch 299 - Avg loss in last 1 epochs: - Train: 0.9950 - Val: 0.9856 - Best val: 0.9854 at epoch 291\n",
      "Epoch 300 - Avg loss in last 1 epochs: - Train: 0.9948 - Val: 0.9856 - Best val: 0.9854 at epoch 291\n",
      "Epoch 301 - Avg loss in last 1 epochs: - Train: 0.9946 - Val: 0.9856 - Best val: 0.9854 at epoch 291\n",
      "Epoch 302 - Avg loss in last 1 epochs: - Train: 0.9947 - Val: 0.9856 - Best val: 0.9854 at epoch 291\n",
      "Epoch 303 - Avg loss in last 1 epochs: - Train: 0.9947 - Val: 0.9856 - Best val: 0.9854 at epoch 291\n",
      "Epoch 304 - Avg loss in last 1 epochs: - Train: 0.9946 - Val: 0.9856 - Best val: 0.9854 at epoch 291\n",
      "Epoch 305 - Avg loss in last 1 epochs: - Train: 0.9945 - Val: 0.9855 - Best val: 0.9854 at epoch 291\n",
      "Epoch 306 - Avg loss in last 1 epochs: - Train: 0.9945 - Val: 0.9854 - Best val: 0.9854 at epoch 307\n",
      "Epoch 307 - Avg loss in last 1 epochs: - Train: 0.9944 - Val: 0.9853 - Best val: 0.9853 at epoch 308\n",
      "Epoch 308 - Avg loss in last 1 epochs: - Train: 0.9941 - Val: 0.9851 - Best val: 0.9851 at epoch 309\n",
      "Epoch 309 - Avg loss in last 1 epochs: - Train: 0.9940 - Val: 0.9850 - Best val: 0.9850 at epoch 310\n",
      "Epoch 310 - Avg loss in last 1 epochs: - Train: 0.9942 - Val: 0.9851 - Best val: 0.9850 at epoch 310\n",
      "Epoch 311 - Avg loss in last 1 epochs: - Train: 0.9940 - Val: 0.9852 - Best val: 0.9850 at epoch 310\n",
      "Epoch 312 - Avg loss in last 1 epochs: - Train: 0.9940 - Val: 0.9853 - Best val: 0.9850 at epoch 310\n",
      "Epoch 313 - Avg loss in last 1 epochs: - Train: 0.9937 - Val: 0.9853 - Best val: 0.9850 at epoch 310\n",
      "Epoch 314 - Avg loss in last 1 epochs: - Train: 0.9938 - Val: 0.9850 - Best val: 0.9850 at epoch 315\n",
      "Epoch 315 - Avg loss in last 1 epochs: - Train: 0.9937 - Val: 0.9847 - Best val: 0.9847 at epoch 316\n",
      "Epoch 316 - Avg loss in last 1 epochs: - Train: 0.9939 - Val: 0.9846 - Best val: 0.9846 at epoch 317\n",
      "Epoch 317 - Avg loss in last 1 epochs: - Train: 0.9938 - Val: 0.9846 - Best val: 0.9846 at epoch 317\n",
      "Epoch 318 - Avg loss in last 1 epochs: - Train: 0.9935 - Val: 0.9847 - Best val: 0.9846 at epoch 317\n",
      "Epoch 319 - Avg loss in last 1 epochs: - Train: 0.9935 - Val: 0.9849 - Best val: 0.9846 at epoch 317\n",
      "Epoch 320 - Avg loss in last 1 epochs: - Train: 0.9935 - Val: 0.9850 - Best val: 0.9846 at epoch 317\n",
      "Epoch 321 - Avg loss in last 1 epochs: - Train: 0.9933 - Val: 0.9849 - Best val: 0.9846 at epoch 317\n",
      "Epoch 322 - Avg loss in last 1 epochs: - Train: 0.9927 - Val: 0.9847 - Best val: 0.9846 at epoch 317\n",
      "Epoch 323 - Avg loss in last 1 epochs: - Train: 0.9932 - Val: 0.9844 - Best val: 0.9844 at epoch 324\n",
      "Epoch 324 - Avg loss in last 1 epochs: - Train: 0.9930 - Val: 0.9841 - Best val: 0.9841 at epoch 325\n",
      "Epoch 325 - Avg loss in last 1 epochs: - Train: 0.9925 - Val: 0.9841 - Best val: 0.9841 at epoch 326\n",
      "Epoch 326 - Avg loss in last 1 epochs: - Train: 0.9927 - Val: 0.9842 - Best val: 0.9841 at epoch 326\n",
      "Epoch 327 - Avg loss in last 1 epochs: - Train: 0.9925 - Val: 0.9843 - Best val: 0.9841 at epoch 326\n",
      "Epoch 328 - Avg loss in last 1 epochs: - Train: 0.9927 - Val: 0.9844 - Best val: 0.9841 at epoch 326\n",
      "Epoch 329 - Avg loss in last 1 epochs: - Train: 0.9926 - Val: 0.9846 - Best val: 0.9841 at epoch 326\n",
      "Epoch 330 - Avg loss in last 1 epochs: - Train: 0.9927 - Val: 0.9848 - Best val: 0.9841 at epoch 326\n",
      "Epoch 331 - Avg loss in last 1 epochs: - Train: 0.9924 - Val: 0.9845 - Best val: 0.9841 at epoch 326\n",
      "Epoch 332 - Avg loss in last 1 epochs: - Train: 0.9923 - Val: 0.9841 - Best val: 0.9841 at epoch 326\n",
      "Epoch 333 - Avg loss in last 1 epochs: - Train: 0.9924 - Val: 0.9838 - Best val: 0.9838 at epoch 334\n",
      "Epoch 334 - Avg loss in last 1 epochs: - Train: 0.9919 - Val: 0.9836 - Best val: 0.9836 at epoch 335\n",
      "Epoch 335 - Avg loss in last 1 epochs: - Train: 0.9921 - Val: 0.9837 - Best val: 0.9836 at epoch 335\n",
      "Epoch 336 - Avg loss in last 1 epochs: - Train: 0.9920 - Val: 0.9838 - Best val: 0.9836 at epoch 335\n",
      "Epoch 337 - Avg loss in last 1 epochs: - Train: 0.9917 - Val: 0.9841 - Best val: 0.9836 at epoch 335\n",
      "Epoch 338 - Avg loss in last 1 epochs: - Train: 0.9919 - Val: 0.9844 - Best val: 0.9836 at epoch 335\n",
      "Epoch 339 - Avg loss in last 1 epochs: - Train: 0.9916 - Val: 0.9845 - Best val: 0.9836 at epoch 335\n",
      "Epoch 340 - Avg loss in last 1 epochs: - Train: 0.9915 - Val: 0.9844 - Best val: 0.9836 at epoch 335\n",
      "Epoch 341 - Avg loss in last 1 epochs: - Train: 0.9916 - Val: 0.9842 - Best val: 0.9836 at epoch 335\n",
      "Epoch 342 - Avg loss in last 1 epochs: - Train: 0.9915 - Val: 0.9840 - Best val: 0.9836 at epoch 335\n",
      "Epoch 343 - Avg loss in last 1 epochs: - Train: 0.9912 - Val: 0.9838 - Best val: 0.9836 at epoch 335\n",
      "Epoch 344 - Avg loss in last 1 epochs: - Train: 0.9914 - Val: 0.9840 - Best val: 0.9836 at epoch 335\n",
      "Epoch 345 - Avg loss in last 1 epochs: - Train: 0.9909 - Val: 0.9842 - Best val: 0.9836 at epoch 335\n",
      "Epoch 346 - Avg loss in last 1 epochs: - Train: 0.9909 - Val: 0.9843 - Best val: 0.9836 at epoch 335\n",
      "Epoch 347 - Avg loss in last 1 epochs: - Train: 0.9906 - Val: 0.9842 - Best val: 0.9836 at epoch 335\n",
      "Epoch 348 - Avg loss in last 1 epochs: - Train: 0.9907 - Val: 0.9840 - Best val: 0.9836 at epoch 335\n",
      "Epoch 349 - Avg loss in last 1 epochs: - Train: 0.9907 - Val: 0.9839 - Best val: 0.9836 at epoch 335\n",
      "Epoch 350 - Avg loss in last 1 epochs: - Train: 0.9907 - Val: 0.9837 - Best val: 0.9836 at epoch 335\n",
      "Epoch 351 - Avg loss in last 1 epochs: - Train: 0.9905 - Val: 0.9834 - Best val: 0.9834 at epoch 352\n",
      "Epoch 352 - Avg loss in last 1 epochs: - Train: 0.9907 - Val: 0.9832 - Best val: 0.9832 at epoch 353\n",
      "Epoch 353 - Avg loss in last 1 epochs: - Train: 0.9905 - Val: 0.9832 - Best val: 0.9832 at epoch 354\n",
      "Epoch 354 - Avg loss in last 1 epochs: - Train: 0.9903 - Val: 0.9834 - Best val: 0.9832 at epoch 354\n",
      "Epoch 355 - Avg loss in last 1 epochs: - Train: 0.9905 - Val: 0.9836 - Best val: 0.9832 at epoch 354\n",
      "Epoch 356 - Avg loss in last 1 epochs: - Train: 0.9905 - Val: 0.9837 - Best val: 0.9832 at epoch 354\n",
      "Epoch 357 - Avg loss in last 1 epochs: - Train: 0.9900 - Val: 0.9838 - Best val: 0.9832 at epoch 354\n",
      "Epoch 358 - Avg loss in last 1 epochs: - Train: 0.9899 - Val: 0.9836 - Best val: 0.9832 at epoch 354\n",
      "Epoch 359 - Avg loss in last 1 epochs: - Train: 0.9898 - Val: 0.9833 - Best val: 0.9832 at epoch 354\n",
      "Epoch 360 - Avg loss in last 1 epochs: - Train: 0.9898 - Val: 0.9832 - Best val: 0.9832 at epoch 354\n",
      "Epoch 361 - Avg loss in last 1 epochs: - Train: 0.9897 - Val: 0.9833 - Best val: 0.9832 at epoch 354\n",
      "Epoch 362 - Avg loss in last 1 epochs: - Train: 0.9897 - Val: 0.9835 - Best val: 0.9832 at epoch 354\n",
      "Epoch 363 - Avg loss in last 1 epochs: - Train: 0.9895 - Val: 0.9839 - Best val: 0.9832 at epoch 354\n",
      "Epoch 364 - Avg loss in last 1 epochs: - Train: 0.9896 - Val: 0.9840 - Best val: 0.9832 at epoch 354\n",
      "Epoch 365 - Avg loss in last 1 epochs: - Train: 0.9894 - Val: 0.9838 - Best val: 0.9832 at epoch 354\n",
      "Epoch 366 - Avg loss in last 1 epochs: - Train: 0.9894 - Val: 0.9835 - Best val: 0.9832 at epoch 354\n",
      "Epoch 367 - Avg loss in last 1 epochs: - Train: 0.9893 - Val: 0.9831 - Best val: 0.9831 at epoch 368\n",
      "Epoch 368 - Avg loss in last 1 epochs: - Train: 0.9893 - Val: 0.9830 - Best val: 0.9830 at epoch 369\n",
      "Epoch 369 - Avg loss in last 1 epochs: - Train: 0.9891 - Val: 0.9828 - Best val: 0.9828 at epoch 370\n",
      "Epoch 370 - Avg loss in last 1 epochs: - Train: 0.9887 - Val: 0.9827 - Best val: 0.9827 at epoch 371\n",
      "Epoch 371 - Avg loss in last 1 epochs: - Train: 0.9889 - Val: 0.9827 - Best val: 0.9827 at epoch 371\n",
      "Epoch 372 - Avg loss in last 1 epochs: - Train: 0.9891 - Val: 0.9827 - Best val: 0.9827 at epoch 371\n",
      "Epoch 373 - Avg loss in last 1 epochs: - Train: 0.9886 - Val: 0.9828 - Best val: 0.9827 at epoch 371\n",
      "Epoch 374 - Avg loss in last 1 epochs: - Train: 0.9886 - Val: 0.9829 - Best val: 0.9827 at epoch 371\n",
      "Epoch 375 - Avg loss in last 1 epochs: - Train: 0.9887 - Val: 0.9828 - Best val: 0.9827 at epoch 371\n",
      "Epoch 376 - Avg loss in last 1 epochs: - Train: 0.9888 - Val: 0.9829 - Best val: 0.9827 at epoch 371\n",
      "Epoch 377 - Avg loss in last 1 epochs: - Train: 0.9885 - Val: 0.9831 - Best val: 0.9827 at epoch 371\n",
      "Epoch 378 - Avg loss in last 1 epochs: - Train: 0.9884 - Val: 0.9832 - Best val: 0.9827 at epoch 371\n",
      "Epoch 379 - Avg loss in last 1 epochs: - Train: 0.9884 - Val: 0.9832 - Best val: 0.9827 at epoch 371\n",
      "Epoch 380 - Avg loss in last 1 epochs: - Train: 0.9884 - Val: 0.9831 - Best val: 0.9827 at epoch 371\n",
      "Epoch 381 - Avg loss in last 1 epochs: - Train: 0.9882 - Val: 0.9830 - Best val: 0.9827 at epoch 371\n",
      "Epoch 382 - Avg loss in last 1 epochs: - Train: 0.9880 - Val: 0.9827 - Best val: 0.9827 at epoch 383\n",
      "Epoch 383 - Avg loss in last 1 epochs: - Train: 0.9880 - Val: 0.9825 - Best val: 0.9825 at epoch 384\n",
      "Epoch 384 - Avg loss in last 1 epochs: - Train: 0.9878 - Val: 0.9823 - Best val: 0.9823 at epoch 385\n",
      "Epoch 385 - Avg loss in last 1 epochs: - Train: 0.9878 - Val: 0.9822 - Best val: 0.9822 at epoch 386\n",
      "Epoch 386 - Avg loss in last 1 epochs: - Train: 0.9877 - Val: 0.9822 - Best val: 0.9822 at epoch 386\n",
      "Epoch 387 - Avg loss in last 1 epochs: - Train: 0.9876 - Val: 0.9824 - Best val: 0.9822 at epoch 386\n",
      "Epoch 388 - Avg loss in last 1 epochs: - Train: 0.9875 - Val: 0.9827 - Best val: 0.9822 at epoch 386\n",
      "Epoch 389 - Avg loss in last 1 epochs: - Train: 0.9876 - Val: 0.9831 - Best val: 0.9822 at epoch 386\n",
      "Epoch 390 - Avg loss in last 1 epochs: - Train: 0.9876 - Val: 0.9835 - Best val: 0.9822 at epoch 386\n",
      "Epoch 391 - Avg loss in last 1 epochs: - Train: 0.9874 - Val: 0.9835 - Best val: 0.9822 at epoch 386\n",
      "Epoch 392 - Avg loss in last 1 epochs: - Train: 0.9873 - Val: 0.9833 - Best val: 0.9822 at epoch 386\n",
      "Epoch 393 - Avg loss in last 1 epochs: - Train: 0.9870 - Val: 0.9830 - Best val: 0.9822 at epoch 386\n",
      "Epoch 394 - Avg loss in last 1 epochs: - Train: 0.9874 - Val: 0.9826 - Best val: 0.9822 at epoch 386\n",
      "Epoch 395 - Avg loss in last 1 epochs: - Train: 0.9872 - Val: 0.9825 - Best val: 0.9822 at epoch 386\n",
      "Epoch 396 - Avg loss in last 1 epochs: - Train: 0.9871 - Val: 0.9826 - Best val: 0.9822 at epoch 386\n",
      "Epoch 397 - Avg loss in last 1 epochs: - Train: 0.9870 - Val: 0.9828 - Best val: 0.9822 at epoch 386\n",
      "Epoch 398 - Avg loss in last 1 epochs: - Train: 0.9872 - Val: 0.9830 - Best val: 0.9822 at epoch 386\n",
      "Epoch 399 - Avg loss in last 1 epochs: - Train: 0.9870 - Val: 0.9831 - Best val: 0.9822 at epoch 386\n",
      "Epoch 400 - Avg loss in last 1 epochs: - Train: 0.9866 - Val: 0.9830 - Best val: 0.9822 at epoch 386\n",
      "Epoch 401 - Avg loss in last 1 epochs: - Train: 0.9867 - Val: 0.9829 - Best val: 0.9822 at epoch 386\n",
      "Epoch 402 - Avg loss in last 1 epochs: - Train: 0.9866 - Val: 0.9829 - Best val: 0.9822 at epoch 386\n",
      "Epoch 403 - Avg loss in last 1 epochs: - Train: 0.9870 - Val: 0.9828 - Best val: 0.9822 at epoch 386\n",
      "Epoch 404 - Avg loss in last 1 epochs: - Train: 0.9867 - Val: 0.9826 - Best val: 0.9822 at epoch 386\n",
      "Epoch 405 - Avg loss in last 1 epochs: - Train: 0.9867 - Val: 0.9825 - Best val: 0.9822 at epoch 386\n",
      "Epoch 406 - Avg loss in last 1 epochs: - Train: 0.9866 - Val: 0.9825 - Best val: 0.9822 at epoch 386\n",
      "Epoch 407 - Avg loss in last 1 epochs: - Train: 0.9864 - Val: 0.9827 - Best val: 0.9822 at epoch 386\n",
      "Epoch 408 - Avg loss in last 1 epochs: - Train: 0.9863 - Val: 0.9830 - Best val: 0.9822 at epoch 386\n",
      "Epoch 409 - Avg loss in last 1 epochs: - Train: 0.9863 - Val: 0.9829 - Best val: 0.9822 at epoch 386\n",
      "Epoch 410 - Avg loss in last 1 epochs: - Train: 0.9863 - Val: 0.9826 - Best val: 0.9822 at epoch 386\n",
      "Epoch 411 - Avg loss in last 1 epochs: - Train: 0.9863 - Val: 0.9825 - Best val: 0.9822 at epoch 386\n",
      "Epoch 412 - Avg loss in last 1 epochs: - Train: 0.9860 - Val: 0.9826 - Best val: 0.9822 at epoch 386\n",
      "Epoch 413 - Avg loss in last 1 epochs: - Train: 0.9860 - Val: 0.9828 - Best val: 0.9822 at epoch 386\n",
      "Epoch 414 - Avg loss in last 1 epochs: - Train: 0.9862 - Val: 0.9829 - Best val: 0.9822 at epoch 386\n",
      "Epoch 415 - Avg loss in last 1 epochs: - Train: 0.9860 - Val: 0.9827 - Best val: 0.9822 at epoch 386\n",
      "Epoch 416 - Avg loss in last 1 epochs: - Train: 0.9859 - Val: 0.9824 - Best val: 0.9822 at epoch 386\n",
      "Epoch 417 - Avg loss in last 1 epochs: - Train: 0.9858 - Val: 0.9821 - Best val: 0.9821 at epoch 418\n",
      "Epoch 418 - Avg loss in last 1 epochs: - Train: 0.9856 - Val: 0.9821 - Best val: 0.9821 at epoch 419\n",
      "Epoch 419 - Avg loss in last 1 epochs: - Train: 0.9860 - Val: 0.9819 - Best val: 0.9819 at epoch 420\n",
      "Epoch 420 - Avg loss in last 1 epochs: - Train: 0.9858 - Val: 0.9820 - Best val: 0.9819 at epoch 420\n",
      "Epoch 421 - Avg loss in last 1 epochs: - Train: 0.9856 - Val: 0.9822 - Best val: 0.9819 at epoch 420\n",
      "Epoch 422 - Avg loss in last 1 epochs: - Train: 0.9857 - Val: 0.9825 - Best val: 0.9819 at epoch 420\n",
      "Epoch 423 - Avg loss in last 1 epochs: - Train: 0.9856 - Val: 0.9826 - Best val: 0.9819 at epoch 420\n",
      "Epoch 424 - Avg loss in last 1 epochs: - Train: 0.9856 - Val: 0.9826 - Best val: 0.9819 at epoch 420\n",
      "Epoch 425 - Avg loss in last 1 epochs: - Train: 0.9854 - Val: 0.9824 - Best val: 0.9819 at epoch 420\n",
      "Epoch 426 - Avg loss in last 1 epochs: - Train: 0.9855 - Val: 0.9822 - Best val: 0.9819 at epoch 420\n",
      "Epoch 427 - Avg loss in last 1 epochs: - Train: 0.9855 - Val: 0.9821 - Best val: 0.9819 at epoch 420\n",
      "Epoch 428 - Avg loss in last 1 epochs: - Train: 0.9852 - Val: 0.9823 - Best val: 0.9819 at epoch 420\n",
      "Epoch 429 - Avg loss in last 1 epochs: - Train: 0.9853 - Val: 0.9824 - Best val: 0.9819 at epoch 420\n",
      "Epoch 430 - Avg loss in last 1 epochs: - Train: 0.9851 - Val: 0.9823 - Best val: 0.9819 at epoch 420\n",
      "Epoch 431 - Avg loss in last 1 epochs: - Train: 0.9849 - Val: 0.9824 - Best val: 0.9819 at epoch 420\n",
      "Epoch 432 - Avg loss in last 1 epochs: - Train: 0.9849 - Val: 0.9825 - Best val: 0.9819 at epoch 420\n",
      "Epoch 433 - Avg loss in last 1 epochs: - Train: 0.9849 - Val: 0.9825 - Best val: 0.9819 at epoch 420\n",
      "Epoch 434 - Avg loss in last 1 epochs: - Train: 0.9848 - Val: 0.9823 - Best val: 0.9819 at epoch 420\n",
      "Epoch 435 - Avg loss in last 1 epochs: - Train: 0.9849 - Val: 0.9823 - Best val: 0.9819 at epoch 420\n",
      "Epoch 436 - Avg loss in last 1 epochs: - Train: 0.9847 - Val: 0.9823 - Best val: 0.9819 at epoch 420\n",
      "Epoch 437 - Avg loss in last 1 epochs: - Train: 0.9847 - Val: 0.9822 - Best val: 0.9819 at epoch 420\n",
      "Epoch 438 - Avg loss in last 1 epochs: - Train: 0.9847 - Val: 0.9822 - Best val: 0.9819 at epoch 420\n",
      "Epoch 439 - Avg loss in last 1 epochs: - Train: 0.9847 - Val: 0.9821 - Best val: 0.9819 at epoch 420\n",
      "Epoch 440 - Avg loss in last 1 epochs: - Train: 0.9848 - Val: 0.9820 - Best val: 0.9819 at epoch 420\n",
      "Epoch 441 - Avg loss in last 1 epochs: - Train: 0.9845 - Val: 0.9820 - Best val: 0.9819 at epoch 420\n",
      "Epoch 442 - Avg loss in last 1 epochs: - Train: 0.9845 - Val: 0.9819 - Best val: 0.9819 at epoch 420\n",
      "Epoch 443 - Avg loss in last 1 epochs: - Train: 0.9845 - Val: 0.9821 - Best val: 0.9819 at epoch 420\n",
      "Epoch 444 - Avg loss in last 1 epochs: - Train: 0.9841 - Val: 0.9824 - Best val: 0.9819 at epoch 420\n",
      "Epoch 445 - Avg loss in last 1 epochs: - Train: 0.9843 - Val: 0.9826 - Best val: 0.9819 at epoch 420\n",
      "Epoch 446 - Avg loss in last 1 epochs: - Train: 0.9842 - Val: 0.9826 - Best val: 0.9819 at epoch 420\n",
      "Epoch 447 - Avg loss in last 1 epochs: - Train: 0.9841 - Val: 0.9826 - Best val: 0.9819 at epoch 420\n",
      "Epoch 448 - Avg loss in last 1 epochs: - Train: 0.9840 - Val: 0.9824 - Best val: 0.9819 at epoch 420\n",
      "Epoch 449 - Avg loss in last 1 epochs: - Train: 0.9839 - Val: 0.9822 - Best val: 0.9819 at epoch 420\n",
      "Epoch 450 - Avg loss in last 1 epochs: - Train: 0.9840 - Val: 0.9819 - Best val: 0.9819 at epoch 451\n",
      "Epoch 451 - Avg loss in last 1 epochs: - Train: 0.9839 - Val: 0.9819 - Best val: 0.9819 at epoch 452\n",
      "Epoch 452 - Avg loss in last 1 epochs: - Train: 0.9840 - Val: 0.9820 - Best val: 0.9819 at epoch 452\n",
      "Epoch 453 - Avg loss in last 1 epochs: - Train: 0.9840 - Val: 0.9820 - Best val: 0.9819 at epoch 452\n",
      "Epoch 454 - Avg loss in last 1 epochs: - Train: 0.9838 - Val: 0.9819 - Best val: 0.9819 at epoch 452\n",
      "Epoch 455 - Avg loss in last 1 epochs: - Train: 0.9839 - Val: 0.9818 - Best val: 0.9818 at epoch 456\n",
      "Epoch 456 - Avg loss in last 1 epochs: - Train: 0.9837 - Val: 0.9817 - Best val: 0.9817 at epoch 457\n",
      "Epoch 457 - Avg loss in last 1 epochs: - Train: 0.9835 - Val: 0.9816 - Best val: 0.9816 at epoch 458\n",
      "Epoch 458 - Avg loss in last 1 epochs: - Train: 0.9835 - Val: 0.9818 - Best val: 0.9816 at epoch 458\n",
      "Epoch 459 - Avg loss in last 1 epochs: - Train: 0.9836 - Val: 0.9821 - Best val: 0.9816 at epoch 458\n",
      "Epoch 460 - Avg loss in last 1 epochs: - Train: 0.9835 - Val: 0.9822 - Best val: 0.9816 at epoch 458\n",
      "Epoch 461 - Avg loss in last 1 epochs: - Train: 0.9835 - Val: 0.9822 - Best val: 0.9816 at epoch 458\n",
      "Epoch 462 - Avg loss in last 1 epochs: - Train: 0.9833 - Val: 0.9821 - Best val: 0.9816 at epoch 458\n",
      "Epoch 463 - Avg loss in last 1 epochs: - Train: 0.9832 - Val: 0.9819 - Best val: 0.9816 at epoch 458\n",
      "Epoch 464 - Avg loss in last 1 epochs: - Train: 0.9831 - Val: 0.9817 - Best val: 0.9816 at epoch 458\n",
      "Epoch 465 - Avg loss in last 1 epochs: - Train: 0.9831 - Val: 0.9816 - Best val: 0.9816 at epoch 458\n",
      "Epoch 466 - Avg loss in last 1 epochs: - Train: 0.9832 - Val: 0.9817 - Best val: 0.9816 at epoch 458\n",
      "Epoch 467 - Avg loss in last 1 epochs: - Train: 0.9827 - Val: 0.9818 - Best val: 0.9816 at epoch 458\n",
      "Epoch 468 - Avg loss in last 1 epochs: - Train: 0.9832 - Val: 0.9818 - Best val: 0.9816 at epoch 458\n",
      "Epoch 469 - Avg loss in last 1 epochs: - Train: 0.9830 - Val: 0.9817 - Best val: 0.9816 at epoch 458\n",
      "Epoch 470 - Avg loss in last 1 epochs: - Train: 0.9828 - Val: 0.9817 - Best val: 0.9816 at epoch 458\n",
      "Epoch 471 - Avg loss in last 1 epochs: - Train: 0.9828 - Val: 0.9818 - Best val: 0.9816 at epoch 458\n",
      "Epoch 472 - Avg loss in last 1 epochs: - Train: 0.9827 - Val: 0.9819 - Best val: 0.9816 at epoch 458\n",
      "Epoch 473 - Avg loss in last 1 epochs: - Train: 0.9828 - Val: 0.9819 - Best val: 0.9816 at epoch 458\n",
      "Epoch 474 - Avg loss in last 1 epochs: - Train: 0.9828 - Val: 0.9817 - Best val: 0.9816 at epoch 458\n",
      "Epoch 475 - Avg loss in last 1 epochs: - Train: 0.9827 - Val: 0.9815 - Best val: 0.9815 at epoch 476\n",
      "Epoch 476 - Avg loss in last 1 epochs: - Train: 0.9825 - Val: 0.9816 - Best val: 0.9815 at epoch 476\n",
      "Epoch 477 - Avg loss in last 1 epochs: - Train: 0.9827 - Val: 0.9813 - Best val: 0.9813 at epoch 478\n",
      "Epoch 478 - Avg loss in last 1 epochs: - Train: 0.9825 - Val: 0.9812 - Best val: 0.9812 at epoch 479\n",
      "Epoch 479 - Avg loss in last 1 epochs: - Train: 0.9824 - Val: 0.9811 - Best val: 0.9811 at epoch 480\n",
      "Epoch 480 - Avg loss in last 1 epochs: - Train: 0.9824 - Val: 0.9811 - Best val: 0.9811 at epoch 480\n",
      "Epoch 481 - Avg loss in last 1 epochs: - Train: 0.9822 - Val: 0.9812 - Best val: 0.9811 at epoch 480\n",
      "Epoch 482 - Avg loss in last 1 epochs: - Train: 0.9822 - Val: 0.9815 - Best val: 0.9811 at epoch 480\n",
      "Epoch 483 - Avg loss in last 1 epochs: - Train: 0.9823 - Val: 0.9816 - Best val: 0.9811 at epoch 480\n",
      "Epoch 484 - Avg loss in last 1 epochs: - Train: 0.9822 - Val: 0.9818 - Best val: 0.9811 at epoch 480\n",
      "Epoch 485 - Avg loss in last 1 epochs: - Train: 0.9821 - Val: 0.9817 - Best val: 0.9811 at epoch 480\n",
      "Epoch 486 - Avg loss in last 1 epochs: - Train: 0.9820 - Val: 0.9815 - Best val: 0.9811 at epoch 480\n",
      "Epoch 487 - Avg loss in last 1 epochs: - Train: 0.9818 - Val: 0.9812 - Best val: 0.9811 at epoch 480\n",
      "Epoch 488 - Avg loss in last 1 epochs: - Train: 0.9818 - Val: 0.9811 - Best val: 0.9811 at epoch 489\n",
      "Epoch 489 - Avg loss in last 1 epochs: - Train: 0.9820 - Val: 0.9810 - Best val: 0.9810 at epoch 490\n",
      "Epoch 490 - Avg loss in last 1 epochs: - Train: 0.9820 - Val: 0.9812 - Best val: 0.9810 at epoch 490\n",
      "Epoch 491 - Avg loss in last 1 epochs: - Train: 0.9816 - Val: 0.9813 - Best val: 0.9810 at epoch 490\n",
      "Epoch 492 - Avg loss in last 1 epochs: - Train: 0.9817 - Val: 0.9815 - Best val: 0.9810 at epoch 490\n",
      "Epoch 493 - Avg loss in last 1 epochs: - Train: 0.9817 - Val: 0.9815 - Best val: 0.9810 at epoch 490\n",
      "Epoch 494 - Avg loss in last 1 epochs: - Train: 0.9814 - Val: 0.9816 - Best val: 0.9810 at epoch 490\n",
      "Epoch 495 - Avg loss in last 1 epochs: - Train: 0.9814 - Val: 0.9815 - Best val: 0.9810 at epoch 490\n",
      "Epoch 496 - Avg loss in last 1 epochs: - Train: 0.9812 - Val: 0.9815 - Best val: 0.9810 at epoch 490\n",
      "Epoch 497 - Avg loss in last 1 epochs: - Train: 0.9816 - Val: 0.9814 - Best val: 0.9810 at epoch 490\n",
      "Epoch 498 - Avg loss in last 1 epochs: - Train: 0.9814 - Val: 0.9815 - Best val: 0.9810 at epoch 490\n",
      "Epoch 499 - Avg loss in last 1 epochs: - Train: 0.9813 - Val: 0.9815 - Best val: 0.9810 at epoch 490\n",
      "Epoch 500 - Avg loss in last 1 epochs: - Train: 0.9813 - Val: 0.9815 - Best val: 0.9810 at epoch 490\n",
      "Epoch 501 - Avg loss in last 1 epochs: - Train: 0.9813 - Val: 0.9813 - Best val: 0.9810 at epoch 490\n",
      "Epoch 502 - Avg loss in last 1 epochs: - Train: 0.9812 - Val: 0.9812 - Best val: 0.9810 at epoch 490\n",
      "Epoch 503 - Avg loss in last 1 epochs: - Train: 0.9810 - Val: 0.9810 - Best val: 0.9810 at epoch 504\n",
      "Epoch 504 - Avg loss in last 1 epochs: - Train: 0.9809 - Val: 0.9808 - Best val: 0.9808 at epoch 505\n",
      "Epoch 505 - Avg loss in last 1 epochs: - Train: 0.9808 - Val: 0.9808 - Best val: 0.9808 at epoch 505\n",
      "Epoch 506 - Avg loss in last 1 epochs: - Train: 0.9810 - Val: 0.9809 - Best val: 0.9808 at epoch 505\n",
      "Epoch 507 - Avg loss in last 1 epochs: - Train: 0.9809 - Val: 0.9810 - Best val: 0.9808 at epoch 505\n",
      "Epoch 508 - Avg loss in last 1 epochs: - Train: 0.9807 - Val: 0.9812 - Best val: 0.9808 at epoch 505\n",
      "Epoch 509 - Avg loss in last 1 epochs: - Train: 0.9807 - Val: 0.9813 - Best val: 0.9808 at epoch 505\n",
      "Epoch 510 - Avg loss in last 1 epochs: - Train: 0.9808 - Val: 0.9813 - Best val: 0.9808 at epoch 505\n",
      "Epoch 511 - Avg loss in last 1 epochs: - Train: 0.9808 - Val: 0.9815 - Best val: 0.9808 at epoch 505\n",
      "Epoch 512 - Avg loss in last 1 epochs: - Train: 0.9806 - Val: 0.9817 - Best val: 0.9808 at epoch 505\n",
      "Epoch 513 - Avg loss in last 1 epochs: - Train: 0.9807 - Val: 0.9818 - Best val: 0.9808 at epoch 505\n",
      "Epoch 514 - Avg loss in last 1 epochs: - Train: 0.9803 - Val: 0.9817 - Best val: 0.9808 at epoch 505\n",
      "Epoch 515 - Avg loss in last 1 epochs: - Train: 0.9807 - Val: 0.9815 - Best val: 0.9808 at epoch 505\n",
      "Epoch 516 - Avg loss in last 1 epochs: - Train: 0.9804 - Val: 0.9813 - Best val: 0.9808 at epoch 505\n",
      "Epoch 517 - Avg loss in last 1 epochs: - Train: 0.9804 - Val: 0.9811 - Best val: 0.9808 at epoch 505\n",
      "Epoch 518 - Avg loss in last 1 epochs: - Train: 0.9804 - Val: 0.9809 - Best val: 0.9808 at epoch 505\n",
      "Epoch 519 - Avg loss in last 1 epochs: - Train: 0.9802 - Val: 0.9807 - Best val: 0.9807 at epoch 520\n",
      "Epoch 520 - Avg loss in last 1 epochs: - Train: 0.9799 - Val: 0.9809 - Best val: 0.9807 at epoch 520\n",
      "Epoch 521 - Avg loss in last 1 epochs: - Train: 0.9801 - Val: 0.9814 - Best val: 0.9807 at epoch 520\n",
      "Epoch 522 - Avg loss in last 1 epochs: - Train: 0.9800 - Val: 0.9815 - Best val: 0.9807 at epoch 520\n",
      "Epoch 523 - Avg loss in last 1 epochs: - Train: 0.9802 - Val: 0.9815 - Best val: 0.9807 at epoch 520\n",
      "Epoch 524 - Avg loss in last 1 epochs: - Train: 0.9801 - Val: 0.9811 - Best val: 0.9807 at epoch 520\n",
      "Epoch 525 - Avg loss in last 1 epochs: - Train: 0.9798 - Val: 0.9806 - Best val: 0.9806 at epoch 526\n",
      "Epoch 526 - Avg loss in last 1 epochs: - Train: 0.9798 - Val: 0.9803 - Best val: 0.9803 at epoch 527\n",
      "Epoch 527 - Avg loss in last 1 epochs: - Train: 0.9797 - Val: 0.9805 - Best val: 0.9803 at epoch 527\n",
      "Epoch 528 - Avg loss in last 1 epochs: - Train: 0.9799 - Val: 0.9810 - Best val: 0.9803 at epoch 527\n",
      "Epoch 529 - Avg loss in last 1 epochs: - Train: 0.9797 - Val: 0.9813 - Best val: 0.9803 at epoch 527\n",
      "Epoch 530 - Avg loss in last 1 epochs: - Train: 0.9795 - Val: 0.9816 - Best val: 0.9803 at epoch 527\n",
      "Epoch 531 - Avg loss in last 1 epochs: - Train: 0.9797 - Val: 0.9816 - Best val: 0.9803 at epoch 527\n",
      "Epoch 532 - Avg loss in last 1 epochs: - Train: 0.9798 - Val: 0.9813 - Best val: 0.9803 at epoch 527\n",
      "Epoch 533 - Avg loss in last 1 epochs: - Train: 0.9795 - Val: 0.9810 - Best val: 0.9803 at epoch 527\n",
      "Epoch 534 - Avg loss in last 1 epochs: - Train: 0.9794 - Val: 0.9807 - Best val: 0.9803 at epoch 527\n",
      "Epoch 535 - Avg loss in last 1 epochs: - Train: 0.9795 - Val: 0.9807 - Best val: 0.9803 at epoch 527\n",
      "Epoch 536 - Avg loss in last 1 epochs: - Train: 0.9792 - Val: 0.9808 - Best val: 0.9803 at epoch 527\n",
      "Epoch 537 - Avg loss in last 1 epochs: - Train: 0.9794 - Val: 0.9810 - Best val: 0.9803 at epoch 527\n",
      "Epoch 538 - Avg loss in last 1 epochs: - Train: 0.9795 - Val: 0.9811 - Best val: 0.9803 at epoch 527\n",
      "Epoch 539 - Avg loss in last 1 epochs: - Train: 0.9794 - Val: 0.9812 - Best val: 0.9803 at epoch 527\n",
      "Epoch 540 - Avg loss in last 1 epochs: - Train: 0.9793 - Val: 0.9814 - Best val: 0.9803 at epoch 527\n",
      "Epoch 541 - Avg loss in last 1 epochs: - Train: 0.9791 - Val: 0.9814 - Best val: 0.9803 at epoch 527\n",
      "Epoch 542 - Avg loss in last 1 epochs: - Train: 0.9792 - Val: 0.9814 - Best val: 0.9803 at epoch 527\n",
      "Epoch 543 - Avg loss in last 1 epochs: - Train: 0.9792 - Val: 0.9813 - Best val: 0.9803 at epoch 527\n",
      "Epoch 544 - Avg loss in last 1 epochs: - Train: 0.9792 - Val: 0.9811 - Best val: 0.9803 at epoch 527\n",
      "Epoch 545 - Avg loss in last 1 epochs: - Train: 0.9791 - Val: 0.9810 - Best val: 0.9803 at epoch 527\n",
      "Epoch 546 - Avg loss in last 1 epochs: - Train: 0.9790 - Val: 0.9810 - Best val: 0.9803 at epoch 527\n",
      "Epoch 547 - Avg loss in last 1 epochs: - Train: 0.9789 - Val: 0.9812 - Best val: 0.9803 at epoch 527\n",
      "Epoch 548 - Avg loss in last 1 epochs: - Train: 0.9791 - Val: 0.9812 - Best val: 0.9803 at epoch 527\n",
      "Epoch 549 - Avg loss in last 1 epochs: - Train: 0.9790 - Val: 0.9812 - Best val: 0.9803 at epoch 527\n",
      "Epoch 550 - Avg loss in last 1 epochs: - Train: 0.9789 - Val: 0.9813 - Best val: 0.9803 at epoch 527\n",
      "Epoch 551 - Avg loss in last 1 epochs: - Train: 0.9787 - Val: 0.9813 - Best val: 0.9803 at epoch 527\n",
      "Epoch 552 - Avg loss in last 1 epochs: - Train: 0.9791 - Val: 0.9813 - Best val: 0.9803 at epoch 527\n",
      "Epoch 553 - Avg loss in last 1 epochs: - Train: 0.9788 - Val: 0.9812 - Best val: 0.9803 at epoch 527\n",
      "Epoch 554 - Avg loss in last 1 epochs: - Train: 0.9787 - Val: 0.9810 - Best val: 0.9803 at epoch 527\n",
      "Epoch 555 - Avg loss in last 1 epochs: - Train: 0.9786 - Val: 0.9809 - Best val: 0.9803 at epoch 527\n",
      "Epoch 556 - Avg loss in last 1 epochs: - Train: 0.9789 - Val: 0.9808 - Best val: 0.9803 at epoch 527\n",
      "Epoch 557 - Avg loss in last 1 epochs: - Train: 0.9785 - Val: 0.9808 - Best val: 0.9803 at epoch 527\n",
      "Epoch 558 - Avg loss in last 1 epochs: - Train: 0.9786 - Val: 0.9808 - Best val: 0.9803 at epoch 527\n",
      "Epoch 559 - Avg loss in last 1 epochs: - Train: 0.9786 - Val: 0.9808 - Best val: 0.9803 at epoch 527\n",
      "Epoch 560 - Avg loss in last 1 epochs: - Train: 0.9786 - Val: 0.9809 - Best val: 0.9803 at epoch 527\n",
      "Epoch 561 - Avg loss in last 1 epochs: - Train: 0.9787 - Val: 0.9810 - Best val: 0.9803 at epoch 527\n",
      "Epoch 562 - Avg loss in last 1 epochs: - Train: 0.9787 - Val: 0.9810 - Best val: 0.9803 at epoch 527\n",
      "Epoch 563 - Avg loss in last 1 epochs: - Train: 0.9786 - Val: 0.9810 - Best val: 0.9803 at epoch 527\n",
      "Epoch 564 - Avg loss in last 1 epochs: - Train: 0.9785 - Val: 0.9809 - Best val: 0.9803 at epoch 527\n",
      "Epoch 565 - Avg loss in last 1 epochs: - Train: 0.9786 - Val: 0.9811 - Best val: 0.9803 at epoch 527\n",
      "Epoch 566 - Avg loss in last 1 epochs: - Train: 0.9783 - Val: 0.9812 - Best val: 0.9803 at epoch 527\n",
      "Epoch 567 - Avg loss in last 1 epochs: - Train: 0.9783 - Val: 0.9813 - Best val: 0.9803 at epoch 527\n",
      "Epoch 568 - Avg loss in last 1 epochs: - Train: 0.9785 - Val: 0.9812 - Best val: 0.9803 at epoch 527\n",
      "Epoch 569 - Avg loss in last 1 epochs: - Train: 0.9784 - Val: 0.9811 - Best val: 0.9803 at epoch 527\n",
      "Epoch 570 - Avg loss in last 1 epochs: - Train: 0.9783 - Val: 0.9809 - Best val: 0.9803 at epoch 527\n",
      "Epoch 571 - Avg loss in last 1 epochs: - Train: 0.9783 - Val: 0.9808 - Best val: 0.9803 at epoch 527\n",
      "Epoch 572 - Avg loss in last 1 epochs: - Train: 0.9783 - Val: 0.9808 - Best val: 0.9803 at epoch 527\n",
      "Epoch 573 - Avg loss in last 1 epochs: - Train: 0.9783 - Val: 0.9808 - Best val: 0.9803 at epoch 527\n",
      "Epoch 574 - Avg loss in last 1 epochs: - Train: 0.9782 - Val: 0.9810 - Best val: 0.9803 at epoch 527\n",
      "Epoch 575 - Avg loss in last 1 epochs: - Train: 0.9779 - Val: 0.9813 - Best val: 0.9803 at epoch 527\n",
      "Epoch 576 - Avg loss in last 1 epochs: - Train: 0.9782 - Val: 0.9813 - Best val: 0.9803 at epoch 527\n",
      "Epoch 577 - Avg loss in last 1 epochs: - Train: 0.9780 - Val: 0.9813 - Best val: 0.9803 at epoch 527\n",
      "Epoch 578 - Avg loss in last 1 epochs: - Train: 0.9780 - Val: 0.9811 - Best val: 0.9803 at epoch 527\n",
      "Epoch 579 - Avg loss in last 1 epochs: - Train: 0.9780 - Val: 0.9809 - Best val: 0.9803 at epoch 527\n",
      "Epoch 580 - Avg loss in last 1 epochs: - Train: 0.9780 - Val: 0.9808 - Best val: 0.9803 at epoch 527\n",
      "Epoch 581 - Avg loss in last 1 epochs: - Train: 0.9780 - Val: 0.9808 - Best val: 0.9803 at epoch 527\n",
      "Epoch 582 - Avg loss in last 1 epochs: - Train: 0.9779 - Val: 0.9809 - Best val: 0.9803 at epoch 527\n",
      "Epoch 583 - Avg loss in last 1 epochs: - Train: 0.9780 - Val: 0.9810 - Best val: 0.9803 at epoch 527\n",
      "Epoch 584 - Avg loss in last 1 epochs: - Train: 0.9779 - Val: 0.9811 - Best val: 0.9803 at epoch 527\n",
      "Epoch 585 - Avg loss in last 1 epochs: - Train: 0.9780 - Val: 0.9811 - Best val: 0.9803 at epoch 527\n",
      "Epoch 586 - Avg loss in last 1 epochs: - Train: 0.9780 - Val: 0.9812 - Best val: 0.9803 at epoch 527\n",
      "Epoch 587 - Avg loss in last 1 epochs: - Train: 0.9780 - Val: 0.9811 - Best val: 0.9803 at epoch 527\n",
      "Epoch 588 - Avg loss in last 1 epochs: - Train: 0.9778 - Val: 0.9811 - Best val: 0.9803 at epoch 527\n",
      "Epoch 589 - Avg loss in last 1 epochs: - Train: 0.9777 - Val: 0.9811 - Best val: 0.9803 at epoch 527\n",
      "Epoch 590 - Avg loss in last 1 epochs: - Train: 0.9779 - Val: 0.9811 - Best val: 0.9803 at epoch 527\n",
      "Epoch 591 - Avg loss in last 1 epochs: - Train: 0.9778 - Val: 0.9811 - Best val: 0.9803 at epoch 527\n",
      "Epoch 592 - Avg loss in last 1 epochs: - Train: 0.9777 - Val: 0.9810 - Best val: 0.9803 at epoch 527\n",
      "Epoch 593 - Avg loss in last 1 epochs: - Train: 0.9776 - Val: 0.9809 - Best val: 0.9803 at epoch 527\n",
      "Epoch 594 - Avg loss in last 1 epochs: - Train: 0.9778 - Val: 0.9809 - Best val: 0.9803 at epoch 527\n",
      "Epoch 595 - Avg loss in last 1 epochs: - Train: 0.9777 - Val: 0.9811 - Best val: 0.9803 at epoch 527\n",
      "Epoch 596 - Avg loss in last 1 epochs: - Train: 0.9778 - Val: 0.9812 - Best val: 0.9803 at epoch 527\n",
      "Epoch 597 - Avg loss in last 1 epochs: - Train: 0.9774 - Val: 0.9814 - Best val: 0.9803 at epoch 527\n",
      "Epoch 598 - Avg loss in last 1 epochs: - Train: 0.9778 - Val: 0.9814 - Best val: 0.9803 at epoch 527\n",
      "Epoch 599 - Avg loss in last 1 epochs: - Train: 0.9778 - Val: 0.9813 - Best val: 0.9803 at epoch 527\n",
      "Epoch 600 - Avg loss in last 1 epochs: - Train: 0.9774 - Val: 0.9812 - Best val: 0.9803 at epoch 527\n",
      "Epoch 601 - Avg loss in last 1 epochs: - Train: 0.9776 - Val: 0.9812 - Best val: 0.9803 at epoch 527\n",
      "Epoch 602 - Avg loss in last 1 epochs: - Train: 0.9776 - Val: 0.9812 - Best val: 0.9803 at epoch 527\n",
      "Epoch 603 - Avg loss in last 1 epochs: - Train: 0.9774 - Val: 0.9813 - Best val: 0.9803 at epoch 527\n",
      "Epoch 604 - Avg loss in last 1 epochs: - Train: 0.9772 - Val: 0.9813 - Best val: 0.9803 at epoch 527\n",
      "Epoch 605 - Avg loss in last 1 epochs: - Train: 0.9774 - Val: 0.9813 - Best val: 0.9803 at epoch 527\n",
      "Epoch 606 - Avg loss in last 1 epochs: - Train: 0.9774 - Val: 0.9812 - Best val: 0.9803 at epoch 527\n",
      "Epoch 607 - Avg loss in last 1 epochs: - Train: 0.9772 - Val: 0.9811 - Best val: 0.9803 at epoch 527\n",
      "Epoch 608 - Avg loss in last 1 epochs: - Train: 0.9773 - Val: 0.9809 - Best val: 0.9803 at epoch 527\n",
      "Epoch 609 - Avg loss in last 1 epochs: - Train: 0.9773 - Val: 0.9807 - Best val: 0.9803 at epoch 527\n",
      "Epoch 610 - Avg loss in last 1 epochs: - Train: 0.9772 - Val: 0.9808 - Best val: 0.9803 at epoch 527\n",
      "Epoch 611 - Avg loss in last 1 epochs: - Train: 0.9772 - Val: 0.9810 - Best val: 0.9803 at epoch 527\n",
      "Epoch 612 - Avg loss in last 1 epochs: - Train: 0.9772 - Val: 0.9811 - Best val: 0.9803 at epoch 527\n",
      "Epoch 613 - Avg loss in last 1 epochs: - Train: 0.9774 - Val: 0.9811 - Best val: 0.9803 at epoch 527\n",
      "Epoch 614 - Avg loss in last 1 epochs: - Train: 0.9771 - Val: 0.9810 - Best val: 0.9803 at epoch 527\n",
      "Epoch 615 - Avg loss in last 1 epochs: - Train: 0.9770 - Val: 0.9811 - Best val: 0.9803 at epoch 527\n",
      "Epoch 616 - Avg loss in last 1 epochs: - Train: 0.9773 - Val: 0.9810 - Best val: 0.9803 at epoch 527\n",
      "Epoch 617 - Avg loss in last 1 epochs: - Train: 0.9772 - Val: 0.9811 - Best val: 0.9803 at epoch 527\n",
      "Epoch 618 - Avg loss in last 1 epochs: - Train: 0.9773 - Val: 0.9813 - Best val: 0.9803 at epoch 527\n",
      "Epoch 619 - Avg loss in last 1 epochs: - Train: 0.9772 - Val: 0.9814 - Best val: 0.9803 at epoch 527\n",
      "Epoch 620 - Avg loss in last 1 epochs: - Train: 0.9772 - Val: 0.9813 - Best val: 0.9803 at epoch 527\n",
      "Epoch 621 - Avg loss in last 1 epochs: - Train: 0.9769 - Val: 0.9811 - Best val: 0.9803 at epoch 527\n",
      "Epoch 622 - Avg loss in last 1 epochs: - Train: 0.9771 - Val: 0.9809 - Best val: 0.9803 at epoch 527\n",
      "Epoch 623 - Avg loss in last 1 epochs: - Train: 0.9769 - Val: 0.9808 - Best val: 0.9803 at epoch 527\n",
      "Epoch 624 - Avg loss in last 1 epochs: - Train: 0.9769 - Val: 0.9807 - Best val: 0.9803 at epoch 527\n",
      "Epoch 625 - Avg loss in last 1 epochs: - Train: 0.9772 - Val: 0.9806 - Best val: 0.9803 at epoch 527\n",
      "Epoch 626 - Avg loss in last 1 epochs: - Train: 0.9768 - Val: 0.9806 - Best val: 0.9803 at epoch 527\n",
      "Epoch 627 - Avg loss in last 1 epochs: - Train: 0.9770 - Val: 0.9809 - Best val: 0.9803 at epoch 527\n",
      "Epoch 628 - Avg loss in last 1 epochs: - Train: 0.9768 - Val: 0.9811 - Best val: 0.9803 at epoch 527\n",
      "Epoch 629 - Avg loss in last 1 epochs: - Train: 0.9769 - Val: 0.9811 - Best val: 0.9803 at epoch 527\n",
      "Epoch 630 - Avg loss in last 1 epochs: - Train: 0.9768 - Val: 0.9811 - Best val: 0.9803 at epoch 527\n",
      "Epoch 631 - Avg loss in last 1 epochs: - Train: 0.9768 - Val: 0.9810 - Best val: 0.9803 at epoch 527\n",
      "Epoch 632 - Avg loss in last 1 epochs: - Train: 0.9769 - Val: 0.9808 - Best val: 0.9803 at epoch 527\n",
      "Epoch 633 - Avg loss in last 1 epochs: - Train: 0.9767 - Val: 0.9808 - Best val: 0.9803 at epoch 527\n",
      "Epoch 634 - Avg loss in last 1 epochs: - Train: 0.9767 - Val: 0.9809 - Best val: 0.9803 at epoch 527\n",
      "Epoch 635 - Avg loss in last 1 epochs: - Train: 0.9767 - Val: 0.9809 - Best val: 0.9803 at epoch 527\n",
      "Epoch 636 - Avg loss in last 1 epochs: - Train: 0.9767 - Val: 0.9809 - Best val: 0.9803 at epoch 527\n",
      "Epoch 637 - Avg loss in last 1 epochs: - Train: 0.9768 - Val: 0.9812 - Best val: 0.9803 at epoch 527\n",
      "Epoch 638 - Avg loss in last 1 epochs: - Train: 0.9769 - Val: 0.9815 - Best val: 0.9803 at epoch 527\n",
      "Epoch 639 - Avg loss in last 1 epochs: - Train: 0.9765 - Val: 0.9816 - Best val: 0.9803 at epoch 527\n",
      "Epoch 640 - Avg loss in last 1 epochs: - Train: 0.9764 - Val: 0.9815 - Best val: 0.9803 at epoch 527\n",
      "Epoch 641 - Avg loss in last 1 epochs: - Train: 0.9766 - Val: 0.9812 - Best val: 0.9803 at epoch 527\n",
      "Epoch 642 - Avg loss in last 1 epochs: - Train: 0.9765 - Val: 0.9808 - Best val: 0.9803 at epoch 527\n",
      "Epoch 643 - Avg loss in last 1 epochs: - Train: 0.9766 - Val: 0.9806 - Best val: 0.9803 at epoch 527\n",
      "Epoch 644 - Avg loss in last 1 epochs: - Train: 0.9764 - Val: 0.9807 - Best val: 0.9803 at epoch 527\n",
      "Epoch 645 - Avg loss in last 1 epochs: - Train: 0.9766 - Val: 0.9809 - Best val: 0.9803 at epoch 527\n",
      "Epoch 646 - Avg loss in last 1 epochs: - Train: 0.9765 - Val: 0.9812 - Best val: 0.9803 at epoch 527\n",
      "Epoch 647 - Avg loss in last 1 epochs: - Train: 0.9767 - Val: 0.9811 - Best val: 0.9803 at epoch 527\n",
      "Epoch 648 - Avg loss in last 1 epochs: - Train: 0.9766 - Val: 0.9808 - Best val: 0.9803 at epoch 527\n",
      "Epoch 649 - Avg loss in last 1 epochs: - Train: 0.9764 - Val: 0.9807 - Best val: 0.9803 at epoch 527\n",
      "Epoch 650 - Avg loss in last 1 epochs: - Train: 0.9766 - Val: 0.9807 - Best val: 0.9803 at epoch 527\n",
      "Epoch 651 - Avg loss in last 1 epochs: - Train: 0.9764 - Val: 0.9808 - Best val: 0.9803 at epoch 527\n",
      "Epoch 652 - Avg loss in last 1 epochs: - Train: 0.9763 - Val: 0.9808 - Best val: 0.9803 at epoch 527\n",
      "Epoch 653 - Avg loss in last 1 epochs: - Train: 0.9764 - Val: 0.9807 - Best val: 0.9803 at epoch 527\n",
      "Epoch 654 - Avg loss in last 1 epochs: - Train: 0.9763 - Val: 0.9806 - Best val: 0.9803 at epoch 527\n",
      "Epoch 655 - Avg loss in last 1 epochs: - Train: 0.9763 - Val: 0.9807 - Best val: 0.9803 at epoch 527\n",
      "Epoch 656 - Avg loss in last 1 epochs: - Train: 0.9765 - Val: 0.9805 - Best val: 0.9803 at epoch 527\n",
      "Epoch 657 - Avg loss in last 1 epochs: - Train: 0.9763 - Val: 0.9804 - Best val: 0.9803 at epoch 527\n",
      "Epoch 658 - Avg loss in last 1 epochs: - Train: 0.9763 - Val: 0.9805 - Best val: 0.9803 at epoch 527\n",
      "Epoch 659 - Avg loss in last 1 epochs: - Train: 0.9764 - Val: 0.9808 - Best val: 0.9803 at epoch 527\n",
      "Epoch 660 - Avg loss in last 1 epochs: - Train: 0.9762 - Val: 0.9810 - Best val: 0.9803 at epoch 527\n",
      "Epoch 661 - Avg loss in last 1 epochs: - Train: 0.9763 - Val: 0.9813 - Best val: 0.9803 at epoch 527\n",
      "Epoch 662 - Avg loss in last 1 epochs: - Train: 0.9763 - Val: 0.9815 - Best val: 0.9803 at epoch 527\n"
     ]
    }
   ],
   "source": [
    "# Tuning LightGCNPlus\n",
    "results = {\n",
    "    \"min_val_losses\": [],\n",
    "    \"params\": []\n",
    "}\n",
    "for K in ks:\n",
    "    for L in layers:\n",
    "        for C in projections:\n",
    "            model = LightGCNPlus(A_tilde, ACT_FN, K, L, INIT_EMBS_STD, DROPOUT, C).to(DEVICE)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "            loss_fn = nn.MSELoss()\n",
    "            print(f\"K={K}, L={L}, C={C}\")\n",
    "            train_rmse, val_rmse = train_model(model, optimizer, loss_fn, train_users, train_items, train_ratings, val_users, val_items, val_ratings, EPOCHS, STOP_THRESHOLD, save_best_model=True, verbosity=1)\n",
    "            report_training_results(train_rmse, val_rmse)\n",
    "            \n",
    "            results[\"min_val_losses\"].append(min(val_rmse))\n",
    "            results[\"params\"].append((K, L, C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report top k best hyperparameter combos\n",
    "TOP_K = 10\n",
    "best_ids = np.argsort(results[\"min_val_losses\"])[:TOP_K]\n",
    "\n",
    "for i in best_ids:\n",
    "    print(f\"Best hyperparameters: {results['params'][i]}\")\n",
    "    print(f\"Best val loss: {results['min_val_losses'][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from postprocess import load_submission_users_items, report_submission_results, create_submission_matrix, reverse_standardize, report_clip_data, to_submission_format, load_means_stds, load_best_val_model\n",
    "\n",
    "# Read model that achieved best validation loss\n",
    "submission_users, submission_items = load_submission_users_items()\n",
    "# Load model inputs\n",
    "# model = load_best_val_model(model_class, ID)\n",
    "# Get predictions for submission\n",
    "\n",
    "raw_pred_ratings = model.get_ratings(submission_users, submission_items).detach().cpu().numpy()\n",
    "report_submission_results(raw_pred_ratings, \"raw\")\n",
    "raw_submission_matrix = create_submission_matrix(raw_pred_ratings, submission_users, submission_items)\n",
    "means, stds = load_means_stds(ID)\n",
    "submission_matrix = reverse_standardize(raw_submission_matrix, means, stds)\n",
    "pred_ratings = submission_matrix[submission_users, submission_items]\n",
    "\n",
    "report_clip_data(pred_ratings)\n",
    "pred_ratings = np.clip(pred_ratings, 1, 5)\n",
    "\n",
    "report_submission_results(pred_ratings, \"clipped\")\n",
    "\n",
    "submission = to_submission_format(submission_users, submission_items, pred_ratings)\n",
    "submission.to_csv('../data/submission_data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
