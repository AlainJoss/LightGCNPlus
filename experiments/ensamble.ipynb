{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble\n",
    "\n",
    "### Scope\n",
    "In this notebook we combine multiple models to decrease the variance in the final predictions, with the aim of improving the $\\text{RMSE}$ score on Kaggle's leaderboard.\n",
    "\n",
    "### About the ensemble model\n",
    "The ensamble model consists of a weighted average of the predictions of the TOP-K models trained in the hyperparameter tuning of the LightGCNPlus model.\n",
    "Mathematically, the ensamble model is defined as follows:\n",
    "$$\n",
    "\\text{Ensemble}(x) = \\sum_{i=1}^{K} w_i \\cdot \\text{Model}_i(x)\n",
    "$$\n",
    "where $w_i$ is the weight of the $i$-th model and $\\text{Model}_i(x)$ is the prediction of the $i$-th model on the input $x$.\n",
    "\n",
    "### Tuning \n",
    "In order to find the optimal weights for the ensamble model, we split the original validation set into two subsets: a fit subset and a test subset. We use the fit subset to try different combinations of the models and the test subset to evaluate the performance of the combination.\n",
    "We then select the combination that gives the best performance on the test subset.\n",
    "\n",
    "### Results\n",
    "As ensambling models radically improves the $\\text{RMSE}$ score on Kaggle's leaderboard, the ensamble model is our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (12001,)\n"
     ]
    }
   ],
   "source": [
    "# load validation set from \"../data/model_state/val_df.csv\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "val_df = pd.read_csv(\"../data/model_state/val_df.csv\")\n",
    "\n",
    "users = val_df[\"val_users\"].values\n",
    "items = val_df[\"val_items\"].values\n",
    "ratings = val_df[\"val_ratings\"].values\n",
    "\n",
    "print(type(users), users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best weights found: [1.89452618e-01 1.50103317e-01 0.00000000e+00 2.85901454e-01\n",
      " 0.00000000e+00 7.32854166e-02 3.90312782e-18 3.00632528e-01\n",
      " 6.93889390e-18 6.24665968e-04]\n",
      "Test MSE: 0.9273070748163846\n",
      "Submission saved to '../data/submission_data/submission.csv'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import minimize\n",
    "import torch\n",
    "from models import LightGCNPlus, load_best_val_model\n",
    "from postprocess import create_submission_matrix, load_means_stds, to_submission_format\n",
    "from load import load_submission_users_items\n",
    "\n",
    "# split data into val and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "TEST_SIZE = 0.5\n",
    "users_val, users_test, items_val, items_test, ratings_val, ratings_test = train_test_split(users, items, ratings, test_size=TEST_SIZE)\n",
    "\n",
    "DEVICE = torch.device('mps')\n",
    "\n",
    "# Model IDs and configurations\n",
    "model_configs = [\n",
    "    (28, 4, (5, ), 1),\n",
    "    (28, 4, (6, ), 1),\n",
    "    (28, 5, (6, 1),1),\n",
    "    (28, 5, (6, ), 1),\n",
    "    (28, 6, (7, ), 1),\n",
    "    (28, 8, (9, ), 1),\n",
    "    (32, 9, (10, ), 1),\n",
    "    (34, 4, (5, ), 1),\n",
    "    (32, 9, (10, 1), 1),\n",
    "    (32, 8, (9,), 1),\n",
    "]\n",
    "\n",
    "def load_and_predict(model_class, config_id, users, items):\n",
    "    ID = f\"{config_id[0]}_{config_id[1]}_{str(config_id[2])}_{config_id[3]}\"\n",
    "    model = load_best_val_model(model_class, ID)\n",
    "    raw_pred_ratings = model.get_ratings(users, items).detach().cpu().numpy()\n",
    "    raw_submission_matrix = create_submission_matrix(raw_pred_ratings, users, items)\n",
    "    pred_ratings = raw_submission_matrix[users, items]\n",
    "    pred_ratings = np.clip(pred_ratings, 1, 5)\n",
    "    return pred_ratings\n",
    "\n",
    "# Load and predict with each model for validation and test sets\n",
    "pred_ratings_list_val = [load_and_predict(LightGCNPlus, config, users_val, items_val) for config in model_configs]\n",
    "pred_ratings_list_test = [load_and_predict(LightGCNPlus, config, users_test, items_test) for config in model_configs]\n",
    "\n",
    "# Define the objective function for optimization\n",
    "def objective(weights, predictions, true_ratings):\n",
    "    ensemble_preds = np.sum(weights[:, None] * predictions, axis=0)\n",
    "    mse = mean_squared_error(true_ratings, ensemble_preds)\n",
    "    return mse\n",
    "\n",
    "# Initial weights (equal weights)\n",
    "initial_weights = np.ones(len(pred_ratings_list_val)) / len(pred_ratings_list_val)\n",
    "\n",
    "# Bounds for the weights (they should be between 0 and 1)\n",
    "bounds = [(0, 1) for _ in range(len(pred_ratings_list_val))]\n",
    "\n",
    "# Constraints (weights should sum to 1)\n",
    "constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}\n",
    "\n",
    "# Find the best weights using the validation set\n",
    "result = minimize(objective, initial_weights, args=(np.array(pred_ratings_list_val), ratings_val), bounds=bounds, constraints=constraints, method='SLSQP')\n",
    "\n",
    "best_weights = result.x\n",
    "print(f\"Best weights found: {best_weights}\")\n",
    "\n",
    "# Evaluate the best weights on the test set\n",
    "ensemble_pred_ratings_test = np.sum(best_weights[:, None] * np.array(pred_ratings_list_test), axis=0)\n",
    "mse_test = mean_squared_error(ratings_test, ensemble_pred_ratings_test)\n",
    "print(f\"Test MSE: {mse_test}\")\n",
    "\n",
    "# Load submission users and items\n",
    "submission_users, submission_items = load_submission_users_items()\n",
    "\n",
    "# Load and predict with each model for the submission set\n",
    "pred_ratings_list_submission = [load_and_predict(LightGCNPlus, config, submission_users, submission_items) for config in model_configs]\n",
    "\n",
    "# Get final ensemble predictions for submission\n",
    "ensemble_pred_ratings_submission = np.sum(best_weights[:, None] * np.array(pred_ratings_list_submission), axis=0)\n",
    "ensemble_pred_ratings_submission = np.clip(ensemble_pred_ratings_submission, 1, 5)\n",
    "\n",
    "# Create the submission dataframe\n",
    "submission = to_submission_format(submission_users, submission_items, ensemble_pred_ratings_submission)\n",
    "\n",
    "# Save the submission to a CSV file\n",
    "submission.to_csv('../data/submission_data/submission.csv', index=False)\n",
    "print(\"Submission saved to '../data/submission_data/submission.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
