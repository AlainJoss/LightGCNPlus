{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test repository in the building process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load import load_data\n",
    "train_df, submission_df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import preprocess\n",
    "\n",
    "A_tilde, standardized_train_ratings, train_users, train_items, means, stds, val_users, val_items, orig_val_ratings, standardized_val_ratings, submission_users, submission_items = preprocess((train_df, submission_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and optimizer hyperparameters\n",
    "L=1\n",
    "K=30\n",
    "INIT_EMBS_STD=0.025\n",
    "LR=0.05\n",
    "WEIGHT_DECAY=1e-04\n",
    "DROPOUT=0.5\n",
    "NUM_HEADS=3\n",
    "\n",
    "# Train loop hyperparameters\n",
    "EPOCHS=10\n",
    "STOP_THRESHOLD=1e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models \n",
    "import importlib \n",
    "importlib.reload(models)\n",
    "from models import ConcatNonLinear\n",
    "from config import DEVICE\n",
    "\n",
    "model = ConcatNonLinear(A_tilde, K, L, INIT_EMBS_STD, DROPOUT, NUM_HEADS).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0 / 10\n",
      "Wha1.shape=torch.Size([11000, 1])\n",
      "Wha2.shape=torch.Size([11000, 1])\n",
      "e.shape=torch.Size([11000, 11000])\n",
      "Wha1.shape=torch.Size([11000, 1])\n",
      "Wha2.shape=torch.Size([11000, 1])\n",
      "e.shape=torch.Size([11000, 11000])\n",
      "Wha1.shape=torch.Size([11000, 1])\n",
      "Wha2.shape=torch.Size([11000, 1])\n",
      "e.shape=torch.Size([11000, 11000])\n",
      "Wha1.shape=torch.Size([11000, 1])\n",
      "Wha2.shape=torch.Size([11000, 1])\n",
      "e.shape=torch.Size([11000, 11000])\n",
      "Wha1.shape=torch.Size([11000, 1])\n",
      "Wha2.shape=torch.Size([11000, 1])\n",
      "e.shape=torch.Size([11000, 11000])\n",
      "Wha1.shape=torch.Size([11000, 1])\n",
      "Wha2.shape=torch.Size([11000, 1])\n",
      "e.shape=torch.Size([11000, 11000])\n",
      "Wha1.shape=torch.Size([11000, 1])\n",
      "Wha2.shape=torch.Size([11000, 1])\n",
      "e.shape=torch.Size([11000, 11000])\n",
      "Wha1.shape=torch.Size([11000, 1])\n",
      "Wha2.shape=torch.Size([11000, 1])\n",
      "e.shape=torch.Size([11000, 11000])\n",
      "Wha1.shape=torch.Size([11000, 1])\n",
      "Wha2.shape=torch.Size([11000, 1])\n",
      "e.shape=torch.Size([11000, 11000])\n",
      "Epoch 0 - Train loss: 1.0277 - Val loss standardized: 1.0319 - Val loss original: 1.0950\n",
      "  1 / 10\n",
      "Wha1.shape=torch.Size([11000, 1])\n",
      "Wha2.shape=torch.Size([11000, 1])\n",
      "e.shape=torch.Size([11000, 11000])\n",
      "Wha1.shape=torch.Size([11000, 1])\n",
      "Wha2.shape=torch.Size([11000, 1])\n",
      "e.shape=torch.Size([11000, 11000])\n",
      "Wha1.shape=torch.Size([11000, 1])\n",
      "Wha2.shape=torch.Size([11000, 1])\n",
      "e.shape=torch.Size([11000, 11000])\n",
      "Wha1.shape=torch.Size([11000, 1])\n",
      "Wha2.shape=torch.Size([11000, 1])\n",
      "e.shape=torch.Size([11000, 11000])\n",
      "Wha1.shape=torch.Size([11000, 1])\n",
      "Wha2.shape=torch.Size([11000, 1])\n",
      "e.shape=torch.Size([11000, 11000])\n"
     ]
    }
   ],
   "source": [
    "from train import train_model\n",
    "# model, optimizer, loss_fn, train_users, train_items, train_ratings, val_users, val_items, val_ratings, n_epochs, improvement_threshold) -> tuple[list, list]:\n",
    "train_rmse, val_rmse_std, val_rmse_orig = train_model(model, optimizer, loss_fn, train_users, train_items, standardized_train_ratings, val_users, val_items, orig_val_ratings, standardized_val_ratings, means, stds, EPOCHS, STOP_THRESHOLD, True, hyper_verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Check training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training stats\n",
    "\n",
    "print(\"Min training loss:\", min(train_rmse))\n",
    "print(\"Min validation loss:\", min(val_rmse_std))\n",
    "print(\"Min validation loss:\", min(val_rmse_orig))\n",
    "print(\"Min validation loss at epoch:\", val_rmse_std.index(min(val_rmse_std)))\n",
    "\n",
    "# Replace values above 10 with 10 in the rmse lists\n",
    "train_rmse_plot = [min(1, x) for x in train_rmse]\n",
    "val_rmse_std_plot = [min(1, x) for x in val_rmse_std]\n",
    "val_rmse_orig_plot = [min(1, x) for x in val_rmse_orig]\n",
    "\n",
    "# Plot train and val rmse\n",
    "plt.plot(train_rmse_plot, label='train')\n",
    "plt.plot(val_rmse_std_plot, label='val std')\n",
    "plt.plot(val_rmse_orig_plot, label='val orig')\n",
    "plt.plot()\n",
    "# annotate min val loss\n",
    "plt.annotate(round(min(val_rmse_orig_plot), 4), (val_rmse_orig_plot.index(min(val_rmse_orig_plot)), min(val_rmse_orig_plot)), textcoords=\"offset points\", xytext=(0,-10), ha='center')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read model that achieved best validation loss\n",
    "model.eval()\n",
    "model.load_state_dict(torch.load(\"../data/logs/best_val_model.pth\"))\n",
    "\n",
    "# Get predictions for submission\n",
    "final_ratings = model.get_ratings(submission_users, submission_items).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check min and max of final_ratings\n",
    "print(\"min:\", final_ratings.min())\n",
    "print(\"max:\", final_ratings.max())\n",
    "print(\"mean:\", final_ratings.mean())\n",
    "\n",
    "# Check distribution of final_ratings\n",
    "plt.hist(final_ratings.flatten(), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import N_u, N_v\n",
    "# Reverse standardization\n",
    "\n",
    "# Fill matrix with predictions\n",
    "final_ratings_matrix = np.zeros((N_u, N_v))\n",
    "final_ratings_matrix[submission_users, submission_items] = final_ratings\n",
    "\n",
    "# Reverse standardization (no mask needed)\n",
    "def reverse_standardization(submission_matrix, means, stds):\n",
    "    # shape of all inputs: (n_users, n_items)\n",
    "    reversed_ratings = submission_matrix * stds + means\n",
    "    return reversed_ratings\n",
    "\n",
    "final_ratings_matrix = reverse_standardization(final_ratings_matrix, means, stds)\n",
    "\n",
    "# extract numpy array from ratings matrix\n",
    "final_ratings = final_ratings_matrix[submission_users, submission_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip at 1 and 5\n",
    "\n",
    "# check min and max of final_ratings_rounded\n",
    "print(\"min:\", final_ratings.min().item())\n",
    "print(\"max:\", final_ratings.max().item())\n",
    "print(\"mean:\", final_ratings.mean().item())\n",
    "\n",
    "# Count the number of values under 1 and over 5\n",
    "count_under_1 = (final_ratings < 1).sum().item()\n",
    "count_over_5 = (final_ratings > 5).sum().item()\n",
    "print(\"count_over_5:\", count_over_5)\n",
    "print(\"count_under_1:\", count_under_1)\n",
    "\n",
    "# Clip the values to be within the range [1, 5]\n",
    "final_ratings = np.clip(final_ratings, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check min and max of final_ratings\n",
    "print(\"min:\", final_ratings.min().item())\n",
    "print(\"max:\", final_ratings.max().item())\n",
    "print(\"mean:\", final_ratings.mean().item())\n",
    "\n",
    "# check distribution of final_ratings\n",
    "plt.hist(final_ratings.flatten(), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save submission\n",
    "def to_submission_format(users, movies, predictions):\n",
    "    return pd.DataFrame(data={'Id': ['r{}_c{}'.format(user + 1, movie + 1) for user, movie in zip(users, movies)],\n",
    "                              'Prediction': predictions})\n",
    "\n",
    "submission = to_submission_format(submission_users, submission_items, final_ratings)\n",
    "\n",
    "submission.to_csv('../data/submission_data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
